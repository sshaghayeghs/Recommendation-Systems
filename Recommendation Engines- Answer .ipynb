{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/0.PNG\" width=\"1000\" height=\"200\">\n",
    "\n",
    "# Building Recommendation Systems in Python\n",
    "\n",
    "**Date:** June 03, 2022 \n",
    "\n",
    "**Presenter:** Shaghayegh Sadeghi\n",
    "\n",
    "## workshop description\n",
    "In this course, students will learn everything they need to know to create their own recommendation engine. Through hands-on exercises, students will get to grips with the two most common systems, collaborative filtering, and content-based filtering. Next, students will learn how to measure similarities like the Jaccard distance and cosine similarity, and how to evaluate the quality of recommendations on test data using the root mean square error (RMSE).\n",
    "\n",
    "**Learning Objectives/Outcomes:** By the end of this course, students will have built their very own movie recommendation engine and be able to apply their Python skills to create these systems for any industry.\n",
    "<img src=\"image/c1.PNG\" width=\"1000\" height=\"200\">\n",
    "\n",
    "<img src=\"https://files.realpython.com/media/Build-a-Recommendation-Engine-With-Collaborative-Filtering_Watermarked.451abc4ecb9f.jpg\" width=\"500\" height=\"500\">\n",
    "\n",
    "\n",
    " **Impact of Recommender systems:**\n",
    " \n",
    " 40% of apps installed in Google Play\n",
    " \n",
    " 60% of watch time in YouTube\n",
    " \n",
    " 35% of purchases in Amzaon\n",
    " \n",
    " 75% of movies watched on NETFLIX\n",
    " \n",
    " ### What are recommendation engines?\n",
    " \n",
    " <img src=\"image/1.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### What kind of data do I need?\n",
    "\n",
    "Recommendation engines use the feedback of users to find new relevant items for them or for others with the assumption that users who have similar preferences in the past are likely to have similar preferences in the future like the example here. Recommendation engines benefit from having a many to many match between the users giving the feedback, and the items receiving the feedback. In other words, a better recommendation can be made for an item that has been given a lot of feedback, and more personalized recommendations can be given for a user that has given a lot of feedback.\n",
    "\n",
    "  <img src=\"image/4.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "  <img src=\"image/2.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    " \n",
    "### What are recommendation engines useful for?\n",
    "**Recommendation Engines**\n",
    "\n",
    "What movie should a viewer watch?\n",
    "\n",
    "Will a diner enjoy a restaurant?\n",
    "\n",
    "**Other Statistical Models**\n",
    "\n",
    "Will a movie sell a lot of tickets?\n",
    "\n",
    "How much is a house worth?\n",
    "\n",
    "\n",
    "  <img src=\"image/3.PNG\" width=\"1000\" height=\"200\">\n",
    "\n",
    "\n",
    "**Exercise 1:** https://jamboard.google.com/d/1eOtXe0g5oBX1cUb2PQpJItDWH4ZAZTp91Crwyo7yr20/edit?usp=sharing \n",
    "<img src=\"https://i1.wp.com/www.firstplaceforhealth.com/wp-content/uploads/2020/03/train-your-brain-gif-2.gif?fit=1200%2C904&ssl=1\" width=\"300\" height=\"100\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       User            Song Title  Skipped Track  Rating\n",
      "0  User_001  Like a Rolling Stone           True       6\n",
      "1  User_001               Imagine          False       2\n",
      "2  User_001       What's Going On          False       9\n",
      "3  User_002               Respect          False       6\n",
      "4  User_003       Good Vibrations           True       0\n"
     ]
    }
   ],
   "source": [
    "#Implicit vs. explicit data\n",
    "listening_history_df=pd.read_csv('listening_history.csv')\n",
    "# Inspect the listening_history_df DataFrame\n",
    "print(listening_history_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating           11\n",
      "Skipped Track     2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of unique values\n",
    "print(listening_history_df[['Rating', 'Skipped Track']].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a histogram of the values in the Rating column\n",
    "listening_history_df['Rating'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "Which of its columns would be considered explicit data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-personalized recommendations\n",
    "They are made to all users, without taking their preferences into account.\n",
    "<img src=\"image/5.PNG\" width=\"800\" height=\"200\">\n",
    "\n",
    "#### Finding the most popular items\n",
    "`book_df` DataFrame:\n",
    "<img src=\"image/6.PNG\" width=\"400\" height=\"100\">\n",
    "```python\n",
    "book_df['book'].value_counts()\n",
    "```\n",
    "<img src=\"image/7.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "```python\n",
    "print(book_df.value_counts().index)\n",
    "```\n",
    "<img src=\"image/8.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "#### Finding the most liked items\n",
    "`user_ratings` DataFrame:\n",
    "<img src=\"image/9.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "```python\n",
    "avg_rating_df = user_ratings[[\"book\", \"rating\"]].groupby(['book']).mean()\n",
    "avg_rating_df.head()\n",
    "```\n",
    "<img src=\"image/10.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "```python\n",
    "sorted_avg_rating_df = avg_rating_df.sort_values(by=\"rating\", ascending=False)\n",
    "sorted_avg_rating_df.head()\n",
    "```\n",
    "<img src=\"image/11.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "#### Finding the most liked popular items\n",
    "```python\n",
    "book_frequency = user_ratings[\"book\"].value_counts()\n",
    "print(book_frequency)\n",
    "```\n",
    "<img src=\"image/12.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "```python\n",
    "frequently_reviewed_books = book_frequency[book_frequency > 100].index\n",
    "print(frequently_reviewed_books)\n",
    "```\n",
    "<img src=\"image/13.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "```python\n",
    "frequent_books_df = user_ratings_df[user_ratings_df[\"book\"].isin(frequently_reviewed_books)]\n",
    "frequent_books_avgs = frequently_reviewed_books[[\"title\", \"rating\"]].groupby('title').mean()\n",
    "print(frequent_books_avgs.sort_values(by=\"rating\", ascending=False).head())\n",
    "```\n",
    "<img src=\"image/14.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "<img src=\"https://i1.wp.com/www.firstplaceforhealth.com/wp-content/uploads/2020/03/train-your-brain-gif-2.gif?fit=1200%2C904&ssl=1\" width=\"300\" height=\"100\">\n",
    "\n",
    "**Exercise:** what is the most frequently watched movie overall in `user_rating` dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>847434962</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1106635946</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1510577970</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1305696483</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>160341</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1479545749</td>\n",
       "      <td>Bloodmoon (1997)</td>\n",
       "      <td>Action|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>160527</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1479544998</td>\n",
       "      <td>Sympathy for the Underdog (1971)</td>\n",
       "      <td>Action|Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>160836</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493844794</td>\n",
       "      <td>Hazard (2005)</td>\n",
       "      <td>Action|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>163937</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1493848789</td>\n",
       "      <td>Blair Witch (2016)</td>\n",
       "      <td>Horror|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>163981</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1493850155</td>\n",
       "      <td>31 (2016)</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp                             title  \\\n",
       "0            1        1     4.0   964982703                  Toy Story (1995)   \n",
       "1            5        1     4.0   847434962                  Toy Story (1995)   \n",
       "2            7        1     4.5  1106635946                  Toy Story (1995)   \n",
       "3           15        1     2.5  1510577970                  Toy Story (1995)   \n",
       "4           17        1     4.5  1305696483                  Toy Story (1995)   \n",
       "...        ...      ...     ...         ...                               ...   \n",
       "100831     610   160341     2.5  1479545749                  Bloodmoon (1997)   \n",
       "100832     610   160527     4.5  1479544998  Sympathy for the Underdog (1971)   \n",
       "100833     610   160836     3.0  1493844794                     Hazard (2005)   \n",
       "100834     610   163937     3.5  1493848789                Blair Witch (2016)   \n",
       "100835     610   163981     3.5  1493850155                         31 (2016)   \n",
       "\n",
       "                                             genres  \n",
       "0       Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1       Adventure|Animation|Children|Comedy|Fantasy  \n",
       "2       Adventure|Animation|Children|Comedy|Fantasy  \n",
       "3       Adventure|Animation|Children|Comedy|Fantasy  \n",
       "4       Adventure|Animation|Children|Comedy|Fantasy  \n",
       "...                                             ...  \n",
       "100831                              Action|Thriller  \n",
       "100832                           Action|Crime|Drama  \n",
       "100833                        Action|Drama|Thriller  \n",
       "100834                              Horror|Thriller  \n",
       "100835                                       Horror  \n",
       "\n",
       "[100836 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ratings_df=pd.read_csv('user_ratings.csv')\n",
    "user_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Forrest Gump (1994)                              329\n",
       "Shawshank Redemption, The (1994)                 317\n",
       "Pulp Fiction (1994)                              307\n",
       "Silence of the Lambs, The (1991)                 279\n",
       "Matrix, The (1999)                               278\n",
       "                                                ... \n",
       "Geostorm (2017)                                    1\n",
       "Barefoot Contessa, The (1954)                      1\n",
       "Passenger, The (Professione: reporter) (1975)      1\n",
       "Ernest Goes to Jail (1990)                         1\n",
       "To Live and Die in L.A. (1985)                     1\n",
       "Name: title, Length: 9719, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the counts of occurrences of each movie title\n",
    "movie_popularity = user_ratings_df[\"title\"].value_counts()\n",
    "movie_popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Forrest Gump (1994)', 'Shawshank Redemption, The (1994)',\n",
      "       'Pulp Fiction (1994)', 'Silence of the Lambs, The (1991)',\n",
      "       'Matrix, The (1999)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(movie_popularity.head().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** you should find the average rating of each movie in the dataset, and then find the movie with the highest average rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     rating\n",
      "title                                      \n",
      "Gena the Crocodile (1969)               5.0\n",
      "True Stories (1986)                     5.0\n",
      "Cosmic Scrat-tastrophe (2015)           5.0\n",
      "Love and Pigeons (1985)                 5.0\n",
      "Red Sorghum (Hong gao liang) (1987)     5.0\n"
     ]
    }
   ],
   "source": [
    "# Find the mean of the ratings given to each title\n",
    "average_rating_df = user_ratings_df[[\"title\", \"rating\"]].groupby('title').mean()\n",
    "\n",
    "# Order the entries by highest average rating to lowest\n",
    "sorted_average_ratings = average_rating_df.sort_values(by='rating', ascending=False)\n",
    "\n",
    "# Inspect the top movies\n",
    "print(sorted_average_ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** you will combine the two previous methods to find the average rating only for movies that have been reviewed more than 50 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Forrest Gump (1994)', 'Shawshank Redemption, The (1994)',\n",
      "       'Pulp Fiction (1994)', 'Silence of the Lambs, The (1991)',\n",
      "       'Matrix, The (1999)', 'Star Wars: Episode IV - A New Hope (1977)',\n",
      "       'Jurassic Park (1993)', 'Braveheart (1995)',\n",
      "       'Terminator 2: Judgment Day (1991)', 'Schindler's List (1993)',\n",
      "       ...\n",
      "       'Knocked Up (2007)', 'X-Men: The Last Stand (2006)',\n",
      "       'Million Dollar Baby (2004)', 'The Devil's Advocate (1997)',\n",
      "       'Bad Boys (1995)', 'Blow (2001)', 'Army of Darkness (1993)',\n",
      "       'Splash (1984)', 'Training Day (2001)', 'Mulholland Drive (2001)'],\n",
      "      dtype='object', length=437)\n"
     ]
    }
   ],
   "source": [
    "# Create a list of only the frequently watched movies\n",
    "movie_popularity = user_ratings_df[\"title\"].value_counts()\n",
    "popular_movies = movie_popularity[movie_popularity > 50].index\n",
    "\n",
    "print(popular_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       userId  movieId  rating   timestamp                 title  \\\n",
      "0           1        1     4.0   964982703      Toy Story (1995)   \n",
      "1           5        1     4.0   847434962      Toy Story (1995)   \n",
      "2           7        1     4.5  1106635946      Toy Story (1995)   \n",
      "3          15        1     2.5  1510577970      Toy Story (1995)   \n",
      "4          17        1     4.5  1305696483      Toy Story (1995)   \n",
      "...       ...      ...     ...         ...                   ...   \n",
      "79246     603     1997     4.0   953925513  Exorcist, The (1973)   \n",
      "79247     606     1997     3.0  1178911117  Exorcist, The (1973)   \n",
      "79248     607     1997     5.0   963079420  Exorcist, The (1973)   \n",
      "79249     608     1997     4.5  1117502891  Exorcist, The (1973)   \n",
      "79250     610     1997     4.0  1479543021  Exorcist, The (1973)   \n",
      "\n",
      "                                            genres  \n",
      "0      Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1      Adventure|Animation|Children|Comedy|Fantasy  \n",
      "2      Adventure|Animation|Children|Comedy|Fantasy  \n",
      "3      Adventure|Animation|Children|Comedy|Fantasy  \n",
      "4      Adventure|Animation|Children|Comedy|Fantasy  \n",
      "...                                            ...  \n",
      "79246                               Horror|Mystery  \n",
      "79247                               Horror|Mystery  \n",
      "79248                               Horror|Mystery  \n",
      "79249                               Horror|Mystery  \n",
      "79250                               Horror|Mystery  \n",
      "\n",
      "[40712 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Use this popular_movies list to filter the original DataFrame\n",
    "popular_movies_rankings = user_ratings_df[user_ratings_df[\"title\"].isin(popular_movies)]\n",
    "\n",
    "# Inspect the movies watched over 50 times\n",
    "print(popular_movies_rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      rating\n",
      "title                                                       \n",
      "Shawshank Redemption, The (1994)                    4.429022\n",
      "Godfather, The (1972)                               4.289062\n",
      "Fight Club (1999)                                   4.272936\n",
      "Cool Hand Luke (1967)                               4.271930\n",
      "Dr. Strangelove or: How I Learned to Stop Worry...  4.268041\n"
     ]
    }
   ],
   "source": [
    "# Find the average rating given to these frequently watched films\n",
    "popular_movies_average_rankings = popular_movies_rankings[[\"title\", \"rating\"]].groupby('title').mean()\n",
    "print(popular_movies_average_rankings.sort_values(by=\"rating\", ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-personalized suggestions\n",
    "\n",
    "### Identifying pairs\n",
    "<img src=\"image/15.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Permutations versus combinations\n",
    "<img src=\"image/16.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "Books seen with `The Great Gatsby` -> `The Catcher in the Rye`\n",
    "\n",
    "Books seen with `The Catcher in the Rye` -> `The Great Gatsby`\n",
    "### Creating the pairing function\n",
    "``` python\n",
    "from itertools import permutations\n",
    "def create_pairs(x):\n",
    "    pairs = pd.DataFrame(list(permutations(x.values, 2)),\n",
    "    columns=['book_a','book_b'])\n",
    "return pairs\n",
    "```\n",
    "- `permutations(list, length_of_permutations))` Generates iterable object containing all permutations\n",
    "- `list()` Converts this object to a usable list\n",
    "- `pd.DataFrame()` Converts the list to a DataFrame containing the columns `book_a` and `book_b`\n",
    "\n",
    "```python\n",
    "#Applying the function to the data\n",
    "book_pairs = book_df.groupby('userId')['book_title'].apply(create_pairs)\n",
    "print(book_pairs.head())\n",
    "```\n",
    "<img src=\"image/17.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "```python\n",
    "#Cleaning up the results\n",
    "book_pairs = book_pairs.reset_index(drop=True)\n",
    "print(book_pairs.head())\n",
    "```\n",
    "<img src=\"image/18.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "```python\n",
    "#Counting the pairings\n",
    "pair_counts = book_pairs.groupby(['book_a', 'book_b']).size()\n",
    "pair_counts_df = pair_counts.to_frame(name = 'size').reset_index()\n",
    "print(pair_counts_df.head())\n",
    "```\n",
    "<img src=\"image/20.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "```python\n",
    "#Looking up recommendations\n",
    "pair_counts_sorted = pair_counts_df.sort_values('size', ascending=False)\n",
    "pair_counts_sorted[pair_counts_sorted['book_a'] == 'Lord of the Rings']\n",
    "```\n",
    "<img src=\"image/21.PNG\" width=\"500\" height=\"100\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i1.wp.com/www.firstplaceforhealth.com/wp-content/uploads/2020/03/train-your-brain-gif-2.gif?fit=1200%2C904&ssl=1\" width=\"300\" height=\"100\">\n",
    "\n",
    "**Exercise** Work through how to find all pairs of movies or all permutations of pairs of movies that have been watched by the same person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         movie_a                           movie_b\n",
      "userId                                                            \n",
      "1      0        Toy Story (1995)           Grumpier Old Men (1995)\n",
      "       1        Toy Story (1995)                       Heat (1995)\n",
      "       2        Toy Story (1995)       Seven (a.k.a. Se7en) (1995)\n",
      "       3        Toy Story (1995)        Usual Suspects, The (1995)\n",
      "       4        Toy Story (1995)        From Dusk Till Dawn (1996)\n",
      "...                          ...                               ...\n",
      "610    1693897         31 (2016)                 Gen-X Cops (1999)\n",
      "       1693898         31 (2016)                  Bloodmoon (1997)\n",
      "       1693899         31 (2016)  Sympathy for the Underdog (1971)\n",
      "       1693900         31 (2016)                     Hazard (2005)\n",
      "       1693901         31 (2016)                Blair Witch (2016)\n",
      "\n",
      "[60793300 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "# Create the function to find all permutations\n",
    "def find_movie_pairs(x):\n",
    "  pairs = pd.DataFrame(list(permutations(x.values, 2)),\n",
    "                       columns=['movie_a', 'movie_b'])\n",
    "  return pairs\n",
    "\n",
    "# Apply the function to the title column and reset the index\n",
    "movie_combinations = user_ratings_df.groupby('userId')['title'].apply(find_movie_pairs)\n",
    "\n",
    "print(movie_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   movie_a                           movie_b\n",
      "0         Toy Story (1995)           Grumpier Old Men (1995)\n",
      "1         Toy Story (1995)                       Heat (1995)\n",
      "2         Toy Story (1995)       Seven (a.k.a. Se7en) (1995)\n",
      "3         Toy Story (1995)        Usual Suspects, The (1995)\n",
      "4         Toy Story (1995)        From Dusk Till Dawn (1996)\n",
      "...                    ...                               ...\n",
      "60793295         31 (2016)                 Gen-X Cops (1999)\n",
      "60793296         31 (2016)                  Bloodmoon (1997)\n",
      "60793297         31 (2016)  Sympathy for the Underdog (1971)\n",
      "60793298         31 (2016)                     Hazard (2005)\n",
      "60793299         31 (2016)                Blair Witch (2016)\n",
      "\n",
      "[60793300 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the title column and reset the index\n",
    "movie_combinations = movie_combinations.reset_index(drop=True)\n",
    "\n",
    "print(movie_combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Work with the movie_combinations DataFrame that you created in the last exercise, and generate a new DataFrame containing the counts of occurrences of each of the pairs within."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_a     movie_b                                   \n",
      "'71 (2014)  (500) Days of Summer (2009)                   1\n",
      "            10 Cloverfield Lane (2016)                    1\n",
      "            127 Hours (2010)                              1\n",
      "            13 Assassins (Jûsan-nin no shikaku) (2010)    1\n",
      "            13 Hours (2016)                               1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate how often each item in movies_a occurs with the items in movies_b\n",
    "combination_counts = movie_combinations.groupby(['movie_a', 'movie_b']).size()\n",
    "\n",
    "# Inspect the results\n",
    "print(combination_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      movie_a                                     movie_b  size\n",
      "0  '71 (2014)                 (500) Days of Summer (2009)     1\n",
      "1  '71 (2014)                  10 Cloverfield Lane (2016)     1\n",
      "2  '71 (2014)                            127 Hours (2010)     1\n",
      "3  '71 (2014)  13 Assassins (Jûsan-nin no shikaku) (2010)     1\n",
      "4  '71 (2014)                             13 Hours (2016)     1\n"
     ]
    }
   ],
   "source": [
    "# Convert the results to a DataFrame and reset the index\n",
    "combination_counts_df = combination_counts.to_frame(name='size').reset_index()\n",
    "print(combination_counts_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Making your first movie recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_a</th>\n",
       "      <th>movie_b</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24019673</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Forrest Gump (1994)</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24023000</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24023672</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Shawshank Redemption, The (1994)</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24024033</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Star Wars: Episode IV - A New Hope (1977)</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24021020</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Jurassic Park (1993)</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   movie_a                                    movie_b  size\n",
       "24019673  Toy Story (1995)                        Forrest Gump (1994)   154\n",
       "24023000  Toy Story (1995)                        Pulp Fiction (1994)   141\n",
       "24023672  Toy Story (1995)           Shawshank Redemption, The (1994)   137\n",
       "24024033  Toy Story (1995)  Star Wars: Episode IV - A New Hope (1977)   134\n",
       "24021020  Toy Story (1995)                       Jurassic Park (1993)   132"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the counts from highest to lowest\n",
    "combination_counts_df=combination_counts_df.sort_values(by='size', ascending=False)\n",
    "\n",
    "# Find the movies most frequently watched by people who watched Thor\n",
    "ToyStory_df = combination_counts_df[combination_counts_df['movie_a'] == 'Toy Story (1995)']\n",
    "ToyStory_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/c2.PNG\" width=\"1000\" height=\"100\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are content-based recommendations?\n",
    "we will move to more targeted models by recommending items based on their similarities to items a user has liked in the past. The recommendations made by finding items with similar attributes are called content-based recommendations.\n",
    "\n",
    "<img src=\"image/22.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Items' attributes or characteristics\n",
    "A big advantage of using an item's attributes over user feedback is that you can make recommendations for any items you have attribute data on. This includes even brand new items that users have not seen yet. Content-based models require us to use any available attributes to build profiles of items in a way that allows us to mathematically compare between them. This allows us for example to find the most similar items and recommend them.\n",
    "\n",
    "<img src=\"image/23.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Vectorizing your attributes\n",
    "This is best done by encoding each item as a vector. It is extremely valuable to have your data in this format so the distance and similarities between items can be easily calculated, which is vital for generating recommendations. \n",
    "<img src=\"image/24.PNG\" width=\"500\" height=\"100\">\n",
    "<img src=\"image/25.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "\n",
    "### Crosstabulation\n",
    "\n",
    "```python\n",
    "pd.crosstab(book_genre_df['Book'], book_genre_df['Genre'])\n",
    "```\n",
    "<img src=\"image/26.PNG\" width=\"500\" height=\"100\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i1.wp.com/www.firstplaceforhealth.com/wp-content/uploads/2020/03/train-your-brain-gif-2.gif?fit=1200%2C904&ssl=1\" width=\"300\" height=\"100\">\n",
    "\n",
    "**Excersie:** \n",
    "How many different movies are contained in `movie_genre_df`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>genre_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>Children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Heat</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Heat</td>\n",
       "      <td>Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Heat</td>\n",
       "      <td>Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sabrina</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sabrina</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Tom and Huck</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Tom and Huck</td>\n",
       "      <td>Children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sudden Death</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GoldenEye</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GoldenEye</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GoldenEye</td>\n",
       "      <td>Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>American President, The</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>American President, The</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>American President, The</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Dracula: Dead and Loving It</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Dracula: Dead and Loving It</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Balto</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Balto</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Balto</td>\n",
       "      <td>Children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Nixon</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Cutthroat Island</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Cutthroat Island</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Cutthroat Island</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Casino</td>\n",
       "      <td>Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Casino</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Sense and Sensibility</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Sense and Sensibility</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Four Rooms</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Ace Ventura: When Nature Calls</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Money Train</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Money Train</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Money Train</td>\n",
       "      <td>Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Money Train</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Money Train</td>\n",
       "      <td>Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Get Shorty</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Get Shorty</td>\n",
       "      <td>Crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name genre_list\n",
       "0                        Toy Story  Adventure\n",
       "1                        Toy Story  Animation\n",
       "2                        Toy Story   Children\n",
       "3                        Toy Story     Comedy\n",
       "4                        Toy Story    Fantasy\n",
       "5                          Jumanji  Adventure\n",
       "6                          Jumanji   Children\n",
       "7                          Jumanji    Fantasy\n",
       "8                 Grumpier Old Men     Comedy\n",
       "9                 Grumpier Old Men    Romance\n",
       "10               Waiting to Exhale     Comedy\n",
       "11               Waiting to Exhale      Drama\n",
       "12               Waiting to Exhale    Romance\n",
       "13     Father of the Bride Part II     Comedy\n",
       "14                            Heat     Action\n",
       "15                            Heat      Crime\n",
       "16                            Heat   Thriller\n",
       "17                         Sabrina     Comedy\n",
       "18                         Sabrina    Romance\n",
       "19                    Tom and Huck  Adventure\n",
       "20                    Tom and Huck   Children\n",
       "21                    Sudden Death     Action\n",
       "22                       GoldenEye     Action\n",
       "23                       GoldenEye  Adventure\n",
       "24                       GoldenEye   Thriller\n",
       "25         American President, The     Comedy\n",
       "26         American President, The      Drama\n",
       "27         American President, The    Romance\n",
       "28     Dracula: Dead and Loving It     Comedy\n",
       "29     Dracula: Dead and Loving It     Horror\n",
       "30                           Balto  Adventure\n",
       "31                           Balto  Animation\n",
       "32                           Balto   Children\n",
       "33                           Nixon      Drama\n",
       "34                Cutthroat Island     Action\n",
       "35                Cutthroat Island  Adventure\n",
       "36                Cutthroat Island    Romance\n",
       "37                          Casino      Crime\n",
       "38                          Casino      Drama\n",
       "39           Sense and Sensibility      Drama\n",
       "40           Sense and Sensibility    Romance\n",
       "41                      Four Rooms     Comedy\n",
       "42  Ace Ventura: When Nature Calls     Comedy\n",
       "43                     Money Train     Action\n",
       "44                     Money Train     Comedy\n",
       "45                     Money Train      Crime\n",
       "46                     Money Train      Drama\n",
       "47                     Money Train   Thriller\n",
       "48                      Get Shorty     Comedy\n",
       "49                      Get Shorty      Crime"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_genre_df=pd.read_csv('movie_genre.csv')\n",
    "movie_genre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_genre_df['name'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excersie:** Get the rows in `movie_genre_df` which have a name equal to Toy Story and save this as `toy_story_genres`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name genre_list\n",
      "0  Toy Story  Adventure\n",
      "1  Toy Story  Animation\n",
      "2  Toy Story   Children\n",
      "3  Toy Story     Comedy\n",
      "4  Toy Story    Fantasy\n"
     ]
    }
   ],
   "source": [
    "# Select only the rows with values in the name column equal to Toy Story\n",
    "toy_story_genres = movie_genre_df[movie_genre_df['name'] == 'Toy Story']\n",
    "\n",
    "# Inspect the subset\n",
    "print(toy_story_genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excersie:** Transform `movie_genre_df` to a table called `movie_cross_table`.\n",
    "\n",
    "Assign the subset of `movie_cross_table` that contains Toy Story to the variable `toy_story_genres_ct` and inspect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre_list  Action  Adventure  Animation  Children  Comedy  Crime  Drama  \\\n",
      "name                                                                       \n",
      "Toy Story        0          1          1         1       1      0      0   \n",
      "\n",
      "genre_list  Fantasy  Horror  Romance  Thriller  \n",
      "name                                            \n",
      "Toy Story         1       0        0         0  \n"
     ]
    }
   ],
   "source": [
    "# Create cross-tabulated DataFrame from name and genre_list columns\n",
    "movie_cross_table = pd.crosstab(movie_genre_df['name'], movie_genre_df['genre_list'])\n",
    "\n",
    "# Select only the rows with Toy Story as the index\n",
    "toy_story_genres_ct = movie_cross_table[movie_cross_table.index == 'Toy Story']\n",
    "print(toy_story_genres_ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excersie:** Inspect the rows corresponding to 'Toy Story' and 'Jumanji' in movie_cross_table. How many genres do they have in common?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre_list  Action  Adventure  Animation  Children  Comedy  Crime  Drama  \\\n",
      "name                                                                       \n",
      "Jumanji          0          1          0         1       0      0      0   \n",
      "\n",
      "genre_list  Fantasy  Horror  Romance  Thriller  \n",
      "name                                            \n",
      "Jumanji           1       0        0         0  \n"
     ]
    }
   ],
   "source": [
    "# Select only the rows with values in the name column equal to Toy Story\n",
    "toy_story_genres = movie_genre_df[movie_genre_df['name'] == 'Jumanji']\n",
    "\n",
    "# Create cross-tabulated DataFrame from name and genre_list columns\n",
    "movie_cross_table = pd.crosstab(movie_genre_df['name'],movie_genre_df['genre_list'])\n",
    "\n",
    "# Select only the rows with Toy Story as the index\n",
    "toy_story_genres_ct = movie_cross_table[movie_cross_table.index == 'Jumanji']\n",
    "print(toy_story_genres_ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making content-based recommendations\n",
    "Jaccard similarity:\n",
    "\n",
    "The Jaccard similarity is the ratio of attributes that two items have in common, divided by the total number of their combined attributes. These are respectively shown by the two orange shaded areas in the Venn diagrams here. It will always be between 0 and 1 and the more attributes the two items have in common, the higher the score.\n",
    "<img src=\"image/27.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "\n",
    "`genres_array_df` :\n",
    "<img src=\"image/28.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Calculating Jaccard similarity between books\n",
    "```python\n",
    "from sklearn.metrics import jaccard_score\n",
    "hobbit_row = book_genre_df.loc['The Hobbit']\n",
    "GOT_row = book_genre_df.loc['A Game of Thrones']\n",
    "print(jaccard_score(hobbit_row, GOT_row))\n",
    "```\n",
    "answer: `0.25`\n",
    "\n",
    "### Finding the distance between all items\n",
    "```python\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "jaccard_distances = pdist(book_genre_df.values, metric='jaccard')\n",
    "print(jaccard_distances)\n",
    "```\n",
    "answer:`[1. 0.5 1. 1. 0.5 1. ]`\n",
    "\n",
    "```python\n",
    "square_jaccard_distances = squareform(jaccard_distances)\n",
    "print(square_jaccard_distances)\n",
    "```\n",
    "answer:\n",
    "```python\n",
    "[[0. 1. 0.5 1. ]\n",
    "[1. 0. 1. 0.5]\n",
    "[0.5 1. 0. 1. ]\n",
    "[1. 0.5 1. 0. ]]```\n",
    "\n",
    "```python\n",
    "jaccard_similarity_array = 1 - square_jaccard_distances\n",
    "print(jaccard_similarity_array)\n",
    "\n",
    "answer:\n",
    "[[1. 0. 0.5 0. ]\n",
    "[0. 1. 0. 0.5]\n",
    "[0.5 0. 1. 0. ]\n",
    "[0. 0.5 0. 1. ]]\n",
    "```\n",
    "### Creating a usable distance table\n",
    "```python\n",
    "distance_df = pd.DataFrame(jaccard_similarity_array,\n",
    "index=genres_array_df['Book'],\n",
    "columns=genres_array_df['Book'])\n",
    "distance_df.head()\n",
    "```\n",
    "<img src=\"image/29.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "\n",
    "```python\n",
    "print(distance_df['The Hobbit']['A Game of Thrones'])\n",
    "```\n",
    "answer: `0.75`\n",
    "\n",
    "```python\n",
    "print(distance_df['The Hobbit']['The Great Gatsby'])\n",
    "```\n",
    "answer: `0.15`\n",
    "\n",
    "### Finding the most similar books\n",
    "```python\n",
    "print(distance_df['The Hobbit'].sort_values(ascending=False))\n",
    "```\n",
    "<img src=\"image/30.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "<img src=\"https://i1.wp.com/www.firstplaceforhealth.com/wp-content/uploads/2020/03/train-your-brain-gif-2.gif?fit=1200%2C904&ssl=1\" width=\"300\" height=\"100\">\n",
    "\n",
    "**Exercise:** Compare the movie `GoldenEye` with the movie `Toy Story`, and `GoldenEye` with `Cutthroat Island` and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "# Import numpy and the Jaccard similarity function\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "# Extract just the rows containing GoldenEye and Toy Story\n",
    "goldeneye_values = movie_cross_table.loc['GoldenEye'].values\n",
    "toy_story_values = movie_cross_table.loc['Toy Story'].values\n",
    "\n",
    "# Find the similarity between GoldenEye and Toy Story\n",
    "print(jaccard_score(goldeneye_values, toy_story_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Repeat for GoldenEye and Skyfall\n",
    "cutthroat_Island_values = movie_cross_table.loc['Cutthroat Island'].values\n",
    "print(jaccard_score(goldeneye_values, cutthroat_Island_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Find the similarities between all movies and store them in a DataFrame for quick and easy lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                            Ace Ventura: When Nature Calls  \\\n",
      "name                                                             \n",
      "Ace Ventura: When Nature Calls                        1.000000   \n",
      "American President, The                               0.333333   \n",
      "Balto                                                 0.000000   \n",
      "Casino                                                0.000000   \n",
      "Cutthroat Island                                      0.000000   \n",
      "\n",
      "name                            American President, The  Balto  Casino  \\\n",
      "name                                                                     \n",
      "Ace Ventura: When Nature Calls                 0.333333    0.0    0.00   \n",
      "American President, The                        1.000000    0.0    0.25   \n",
      "Balto                                          0.000000    1.0    0.00   \n",
      "Casino                                         0.250000    0.0    1.00   \n",
      "Cutthroat Island                               0.200000    0.2    0.00   \n",
      "\n",
      "name                            Cutthroat Island  Dracula: Dead and Loving It  \\\n",
      "name                                                                            \n",
      "Ace Ventura: When Nature Calls               0.0                         0.50   \n",
      "American President, The                      0.2                         0.25   \n",
      "Balto                                        0.2                         0.00   \n",
      "Casino                                       0.0                         0.00   \n",
      "Cutthroat Island                             1.0                         0.00   \n",
      "\n",
      "name                            Father of the Bride Part II  Four Rooms  \\\n",
      "name                                                                      \n",
      "Ace Ventura: When Nature Calls                     1.000000    1.000000   \n",
      "American President, The                            0.333333    0.333333   \n",
      "Balto                                              0.000000    0.000000   \n",
      "Casino                                             0.000000    0.000000   \n",
      "Cutthroat Island                                   0.000000    0.000000   \n",
      "\n",
      "name                            Get Shorty  GoldenEye  ...  Heat  Jumanji  \\\n",
      "name                                                   ...                  \n",
      "Ace Ventura: When Nature Calls    0.500000        0.0  ...  0.00      0.0   \n",
      "American President, The           0.250000        0.0  ...  0.00      0.0   \n",
      "Balto                             0.000000        0.2  ...  0.00      0.5   \n",
      "Casino                            0.333333        0.0  ...  0.25      0.0   \n",
      "Cutthroat Island                  0.000000        0.5  ...  0.20      0.2   \n",
      "\n",
      "name                            Money Train     Nixon   Sabrina  \\\n",
      "name                                                              \n",
      "Ace Ventura: When Nature Calls     0.200000  0.000000  0.500000   \n",
      "American President, The            0.333333  0.333333  0.666667   \n",
      "Balto                              0.000000  0.000000  0.000000   \n",
      "Casino                             0.400000  0.500000  0.000000   \n",
      "Cutthroat Island                   0.142857  0.000000  0.250000   \n",
      "\n",
      "name                            Sense and Sensibility  Sudden Death  \\\n",
      "name                                                                  \n",
      "Ace Ventura: When Nature Calls               0.000000      0.000000   \n",
      "American President, The                      0.666667      0.000000   \n",
      "Balto                                        0.000000      0.000000   \n",
      "Casino                                       0.333333      0.000000   \n",
      "Cutthroat Island                             0.250000      0.333333   \n",
      "\n",
      "name                            Tom and Huck  Toy Story  Waiting to Exhale  \n",
      "name                                                                        \n",
      "Ace Ventura: When Nature Calls      0.000000   0.200000           0.333333  \n",
      "American President, The             0.000000   0.142857           1.000000  \n",
      "Balto                               0.666667   0.600000           0.000000  \n",
      "Casino                              0.000000   0.000000           0.250000  \n",
      "Cutthroat Island                    0.250000   0.142857           0.200000  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import functions from scipy\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# Calculate all pairwise distances\n",
    "jaccard_distances = pdist(movie_cross_table.values, metric='jaccard')\n",
    "\n",
    "# Convert the distances to a square matrix\n",
    "jaccard_similarity_array = 1 - squareform(jaccard_distances)\n",
    "\n",
    "# Wrap the array in a pandas DataFrame\n",
    "jaccard_similarity_df = pd.DataFrame(jaccard_similarity_array, index=movie_cross_table.index, columns=movie_cross_table.index)\n",
    "\n",
    "# Print the top 5 rows of the DataFrame\n",
    "print(jaccard_similarity_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Use this new DataFrame to suggest a movie recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "Jumanji                           1.000000\n",
      "Tom and Huck                      0.666667\n",
      "Toy Story                         0.600000\n",
      "Balto                             0.500000\n",
      "Cutthroat Island                  0.200000\n",
      "GoldenEye                         0.200000\n",
      "Waiting to Exhale                 0.000000\n",
      "Four Rooms                        0.000000\n",
      "American President, The           0.000000\n",
      "Casino                            0.000000\n",
      "Dracula: Dead and Loving It       0.000000\n",
      "Father of the Bride Part II       0.000000\n",
      "Grumpier Old Men                  0.000000\n",
      "Get Shorty                        0.000000\n",
      "Heat                              0.000000\n",
      "Money Train                       0.000000\n",
      "Nixon                             0.000000\n",
      "Sabrina                           0.000000\n",
      "Sense and Sensibility             0.000000\n",
      "Sudden Death                      0.000000\n",
      "Ace Ventura: When Nature Calls    0.000000\n",
      "Name: Jumanji, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Wrap the preloaded array in a DataFrame\n",
    "jaccard_similarity_df = pd.DataFrame(jaccard_similarity_array, index=movie_cross_table.index, columns=movie_cross_table.index)\n",
    "\n",
    "# Find the values for the movie Thor\n",
    "jaccard_similarity_series = jaccard_similarity_df.loc['Jumanji']\n",
    "\n",
    "# Sort these values from highest to lowest\n",
    "ordered_similarities = jaccard_similarity_series.sort_values(ascending=False)\n",
    "\n",
    "# Print the results\n",
    "print(ordered_similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "Based on your analysis, which movie in the dataset is most similar to Jumanji?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-based similarities\n",
    "\n",
    "### Working without clear attributes\n",
    "\n",
    "Unfortunately in the real world, this is often not the case as attribute labels such as book genres might not be available. Thankfully if there is text tied to an item then we may still be in luck. This could be a plot summary, an item description, or even the contents of a book itself. For this kind of data, we use \"Term Frequency Inverse Document Frequency\" or TF-IDF to transform the text into something usable.\n",
    "\n",
    "<img src=\"image/31.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Term frequency inverse document frequency\n",
    "\n",
    "TF-IDF divides the number of times a word occurs in a document by a measure of what proportion of all the documents a word occurs in. This has the effect of reducing the value of common words while increasing the weight of words that do not occur in many documents.\n",
    "<img src=\"image/32.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "`book_summary_df` :\n",
    "<img src=\"image/33.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Instantiate the vectorizer:\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfvec = TfidfVectorizer(min_df=2, max_df=0.7)\n",
    "```\n",
    "- min_df limits our features to only those that have occurred in at least two documents. Useful as terms occurring once are not valuable for finding similarities.\n",
    "- We should also remove words that are too common using max_df. By setting this to point seven, words that occur in more than 70% of the descriptions will be excluded.\n",
    "\n",
    "\n",
    "### Vectorizing the data\n",
    "```python\n",
    "vectorized_data = tfidfvec.fit_transform(book_summary_df['Descriptions'])\n",
    "print(tfidfvec.get_feature_names)\n",
    "```\n",
    "Answer:\n",
    "\n",
    "`['age', 'ancient', 'angry', 'brave', 'battle', 'fellow', 'game', 'general', ...]`\n",
    "```python\n",
    "print(vectorized_data.to_array())\n",
    "\n",
    "Answer:\n",
    "[[0.21, 0.53, 0.41, 0.64, 0.01, 0.02, ...\n",
    "[0.31, 0.00, 0.42, 0.03, 0.00, 0.73, ...\n",
    "[..., ..., ..., ..., ..., ..., ...\n",
    "```\n",
    "\n",
    "### Formatting the data\n",
    "```python\n",
    "tfidf_df = pd.DataFrame(vectorized_data.toarray(),\n",
    "columns=tfidfvec.get_feature_names())\n",
    "tfidf_df.index = book_summary_df['Book']\n",
    "print(tfidf_df)\n",
    "```\n",
    "<img src=\"image/34.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Cosine similarity\n",
    "\n",
    "As we advance from Boolean features to continuous TF-IDF values, we will use a metric that's better at measuring between items that have more variation in their data; cosine similarity. We won't go into it in depth here, but mathematically, it's the measure of the angle between two documents in the high dimensional metric space as seen on this two-dimensional example. All values are between 0 and 1 where 1 is an exact match.\n",
    "\n",
    "<img src=\"image/35.PNG\" width=\"300\" height=\"100\">\n",
    "\n",
    "```python\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Find similarity between all items\n",
    "cosine_similarity_array = cosine_similarity(tfidf_summary_df)\n",
    "# Find similarity between two items\n",
    "cosine_similarity(tfidf_df.loc['The Hobbit'].values.reshape(1, -1),\n",
    "tfidf_df.loc['Macbeth'].values.reshape(1, -1))\n",
    "```\n",
    "\n",
    "<img src=\"https://i1.wp.com/www.firstplaceforhealth.com/wp-content/uploads/2020/03/train-your-brain-gif-2.gif?fit=1200%2C904&ssl=1\" width=\"300\" height=\"100\">\n",
    "\n",
    "**Exercise:** Work with the `df_plots` DataFrame. It contains movies' names in the Title column and their plots in the Plot column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ace Ventura: When Nature Calls</td>\n",
       "      <td>In the Himalayas, after a failed rescue missio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dracula: Dead and Loving It</td>\n",
       "      <td>In 1893, Solicitor Thomas Renfield travels fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>The film begins four years after the events of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Four Rooms</td>\n",
       "      <td>On New Year's Eve, bellhop Sam (Marc Lawrence)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>The feud between Max (Walter Matthau) and John...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>In 1969, Alan Parrish lives with his parents S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sudden Death</td>\n",
       "      <td>Darren McCord is a French Canadian-born firefi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tom and Huck</td>\n",
       "      <td>One dark stormy night, Injun Joe goes to meet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>A group of living toys, who assume lifelessnes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Four friends (Savannah, Robin, Bernadine, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GoldenEye</td>\n",
       "      <td>In 1986, MI6 agents James Bond and Alec Trevel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Skyfall</td>\n",
       "      <td>MI6 agents James Bond and Eve In Istanbul, MI6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Title  \\\n",
       "0   Ace Ventura: When Nature Calls   \n",
       "1      Dracula: Dead and Loving It   \n",
       "2      Father of the Bride Part II   \n",
       "3                       Four Rooms   \n",
       "4                 Grumpier Old Men   \n",
       "5                          Jumanji   \n",
       "6                     Sudden Death   \n",
       "7                     Tom and Huck   \n",
       "8                        Toy Story   \n",
       "9                Waiting to Exhale   \n",
       "10                       GoldenEye   \n",
       "11                         Skyfall   \n",
       "\n",
       "                                                 Plot  \n",
       "0   In the Himalayas, after a failed rescue missio...  \n",
       "1   In 1893, Solicitor Thomas Renfield travels fro...  \n",
       "2   The film begins four years after the events of...  \n",
       "3   On New Year's Eve, bellhop Sam (Marc Lawrence)...  \n",
       "4   The feud between Max (Walter Matthau) and John...  \n",
       "5   In 1969, Alan Parrish lives with his parents S...  \n",
       "6   Darren McCord is a French Canadian-born firefi...  \n",
       "7   One dark stormy night, Injun Joe goes to meet ...  \n",
       "8   A group of living toys, who assume lifelessnes...  \n",
       "9   Four friends (Savannah, Robin, Bernadine, and ...  \n",
       "10  In 1986, MI6 agents James Bond and Alec Trevel...  \n",
       "11  MI6 agents James Bond and Eve In Istanbul, MI6...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plots=pd.read_excel('df_plots.xlsx')\n",
    "df_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '10', '100', '1893', '1969', '1986', '1991', '1992', '1995', '1997', '309', '404', '500', '900', 'abandoned', 'abbey', 'abbot', 'about', 'above', 'abraham', 'abused', 'acala', 'access', 'accident', 'accidentally', 'accompanied', 'accomplice', 'account', 'accounts', 'accuses', 'ace', 'achieved', 'act', 'action', 'activates', 'adapted', 'addition', 'administrator', 'admiring', 'admits', 'adopts', 'adult', 'advances', 'advice', 'advised', 'advises', 'affectionately', 'africa', 'african', 'after', 'afterward', 'afterwards', 'again', 'against', 'agent', 'agents', 'aggressively', 'agrees', 'airborne', 'aircraft', 'alan', 'alec', 'alerts', 'alexandre', 'alibi', 'alien', 'alive', 'all', 'allison', 'allow', 'allowed', 'allowing', 'alone', 'along', 'alongside', 'also', 'alternate', 'although', 'always', 'amanda', 'ambulance', 'among', 'amorous', 'an', 'anchor', 'and', 'anders', 'andy', 'angela', 'angrily', 'angry', 'animal', 'animals', 'animated', 'ann', 'annie', 'announce', 'announces', 'annual', 'another', 'antennae', 'antonio', 'any', 'anyone', 'apologize', 'apologizes', 'apology', 'appears', 'appointed', 'approached', 'approves', 'are', 'area', 'arena', 'argue', 'arguing', 'argument', 'ariel', 'arkady', 'arkhangelsk', 'arm', 'armed', 'arms', 'army', 'around', 'arrange', 'arrangement', 'arrested', 'arrival', 'arrive', 'arrives', 'arriving', 'as', 'ashes', 'asked', 'asks', 'assassination', 'assaults', 'assessment', 'assets', 'assigned', 'assigns', 'assistant', 'assists', 'assume', 'assumed', 'assumes', 'aston', 'astral', 'asylum', 'at', 'atmospheric', 'atop', 'attack', 'attacked', 'attacks', 'attempt', 'attempting', 'attempts', 'attend', 'attending', 'attic', 'attorney', 'audience', 'aunt', 'australian', 'averting', 'avoid', 'avoiding', 'awaiting', 'aware', 'away', 'axis', 'baby', 'back', 'bait', 'ball', 'banderas', 'bank', 'banks', 'bare', 'barely', 'base', 'based', 'basketball', 'bat', 'bathroom', 'bats', 'batteries', 'battlefield', 'battles', 'be', 'beach', 'beacon', 'beals', 'bearing', 'beauty', 'because', 'becky', 'become', 'becomes', 'becoming', 'bed', 'bedroom', 'been', 'beer', 'before', 'befriends', 'begging', 'begin', 'begins', 'behavior', 'behind', 'being', 'believe', 'believed', 'believes', 'believing', 'bellhop', 'belongings', 'below', 'belt', 'bender', 'beneath', 'bentley', 'bernadine', 'bernie', 'beside', 'bet', 'betraying', 'better', 'betty', 'between', 'bible', 'bicycle', 'big', 'bill', 'billions', 'birth', 'birthday', 'bisexual', 'biting', 'blackhawks', 'blast', 'blend', 'blinds', 'block', 'blocked', 'blood', 'blow', 'blowing', 'bo', 'board', 'boarding', 'boat', 'body', 'bodyguards', 'bombs', 'bonai', 'bond', 'booby', 'boris', 'born', 'boss', 'boston', 'both', 'bottle', 'bought', 'box', 'boy', 'boys', 'brantford', 'break', 'breaking', 'breaks', 'bride', 'briefs', 'bring', 'brings', 'britain', 'broadcasting', 'brother', 'brown', 'bryan', 'bucket', 'building', 'bull', 'bulldog', 'bullies', 'bureau', 'burgess', 'buried', 'burn', 'burns', 'business', 'but', 'buttock', 'buy', 'buzz', 'by', 'cadby', 'cadenet', 'cage', 'calamity', 'calderón', 'call', 'called', 'calls', 'calm', 'came', 'can', 'canada', 'canadian', 'cancel', 'canisters', 'captive', 'capture', 'captured', 'captures', 'capuchin', 'car', 'care', 'career', 'carfax', 'caribbean', 'carl', 'carla', 'carlo', 'carnivorous', 'carol', 'carried', 'carrying', 'cartoons', 'carved', 'case', 'cash', 'casino', 'cast', 'castle', 'casts', 'cat', 'catch', 'catering', 'catfish', 'caught', 'cauldron', 'causes', 'causing', 'cave', 'caves', 'celibacy', 'cell', 'center', 'chagrin', 'chairman', 'challenge', 'challenges', 'champagne', 'chance', 'change', 'channel', 'chaos', 'chapel', 'charge', 'charged', 'charges', 'chase', 'chases', 'chasm', 'cheat', 'cheating', 'chemical', 'chest', 'chester', 'chicago', 'chief', 'child', 'childhood', 'childish', 'children', 'chimera', 'chinese', 'chooses', 'chopper', 'chops', 'christmas', 'chronic', 'chuck', 'church', 'cia', 'cigarette', 'circle', 'civic', 'civil', 'claim', 'claiming', 'claims', 'claw', 'clay', 'clear', 'clerical', 'cliffhanger', 'climbs', 'clock', 'closed', 'clothes', 'club', 'coast', 'codenamed', 'coffin', 'coherent', 'collaboration', 'colonel', 'combustible', 'come', 'comes', 'coming', 'commandeered', 'commanding', 'commercial', 'committee', 'community', 'company', 'complete', 'completely', 'completes', 'complicate', 'computer', 'conceal', 'concealed', 'concealing', 'concern', 'concludes', 'condition', 'confined', 'confirms', 'confrontations', 'confronting', 'confronts', 'consciousness', 'construction', 'consul', 'consulate', 'consults', 'contact', 'containing', 'contented', 'continue', 'control', 'controlled', 'conversation', 'converting', 'conveyor', 'convinced', 'convinces', 'convincing', 'cool', 'cooled', 'correspondent', 'cossacks', 'could', 'count', 'country', 'courageously', 'court', 'coven', 'covered', 'crane', 'crash', 'creatively', 'credits', 'creeping', 'crew', 'crime', 'criminal', 'crocodile', 'crocodiles', 'cross', 'crowd', 'cruise', 'crypt', 'cryptic', 'crystal', 'cuba', 'culminates', 'cup', 'curtain', 'cut', 'cutting', 'cyanide', 'cyberterrorism', 'cynical', 'dachshund', 'dagger', 'dahl', 'damages', 'damaging', 'dance', 'dangled', 'danny', 'dark', 'darren', 'dart', 'dartboard', 'darts', 'daryl', 'dates', 'dating', 'daughter', 'david', 'davis', 'day', 'days', 'db5', 'de', 'dead', 'deal', 'death', 'deaths', 'debris', 'decide', 'decides', 'deciding', 'declare', 'declared', 'decline', 'decrypt', 'deduces', 'defence', 'defends', 'delay', 'deliberately', 'delighted', 'delivered', 'delivers', 'delivery', 'demolish', 'demolition', 'demonstration', 'denial', 'department', 'departure', 'depression', 'deprivation', 'descended', 'describing', 'desk', 'despair', 'despite', 'destroy', 'destroyed', 'destroying', 'destroys', 'destruction', 'detaching', 'details', 'determined', 'determines', 'devastate', 'devil', 'devises', 'devotion', 'diana', 'dice', 'did', 'didn', 'died', 'dies', 'different', 'differing', 'difficulties', 'digging', 'dimitri', 'dinner', 'directed', 'director', 'directs', 'disables', 'disappearance', 'disappeared', 'disapproves', 'disarm', 'disavowing', 'disconnecting', 'discover', 'discovered', 'discovering', 'discovers', 'discussion', 'disfigured', 'disguise', 'disguised', 'dish', 'display', 'disregards', 'dissolution', 'distract', 'distracts', 'distraught', 'divorce', 'do', 'dobermans', 'doc', 'doctor', 'does', 'doesn', 'dog', 'doll', 'dollar', 'dollars', 'don', 'door', 'dosage', 'doughnut', 'douglas', 'down', 'dowry', 'dr', 'dracula', 'draining', 'drains', 'drama', 'dramatically', 'dream', 'dressed', 'drinks', 'drive', 'driveway', 'driving', 'drop', 'dropped', 'dropping', 'drops', 'drove', 'drugged', 'drumbeats', 'drunk', 'due', 'dumping', 'dumps', 'during', 'dyes', 'each', 'earlier', 'early', 'earthquake', 'easily', 'eastern', 'economic', 'edison', 'eight', 'either', 'elated', 'electromagnetic', 'electronic', 'elephant', 'elephants', 'eliminating', 'eloped', 'eluding', 'embark', 'emergency', 'emerges', 'emily', 'emmett', 'emotional', 'employer', 'employs', 'empty', 'ems', 'encounter', 'encounters', 'encourages', 'end', 'ends', 'enduring', 'energetic', 'engaged', 'engagement', 'england', 'english', 'enjoy', 'enjoying', 'enough', 'ensues', 'ensuing', 'ensure', 'enter', 'enters', 'entire', 'entry', 'era', 'error', 'erupts', 'escalations', 'escape', 'escaped', 'escapes', 'escaping', 'escort', 'escorted', 'eurocopter', 'evades', 'evading', 'eve', 'even', 'events', 'eventually', 'ever', 'everyone', 'everything', 'evidence', 'ex', 'exact', 'exam', 'examinations', 'except', 'excuses', 'executed', 'executive', 'expecting', 'experience', 'experiencing', 'explaining', 'explains', 'explode', 'explodes', 'exploding', 'explosives', 'express', 'eye', 'eyed', 'face', 'facility', 'factory', 'fail', 'failed', 'fails', 'faked', 'fall', 'falling', 'falls', 'family', 'famous', 'fancy', 'fantasy', 'fast', 'fatally', 'father', 'favorite', 'fear', 'feature', 'features', 'feelings', 'fellow', 'female', 'fertilizer', 'festival', 'feud', 'few', 'fiance', 'fictional', 'field', 'fieldwork', 'fight', 'fighter', 'fighting', 'fights', 'figure', 'fills', 'film', 'final', 'finalize', 'finally', 'finals', 'financial', 'find', 'finding', 'finds', 'finish', 'finishes', 'finishing', 'finn', 'fire', 'firefighter', 'first', 'fishing', 'five', 'fix', 'flee', 'flirts', 'flooding', 'floor', 'flummoxed', 'fly', 'flying', 'follow', 'following', 'follows', 'for', 'forced', 'forces', 'forcing', 'formally', 'former', 'forward', 'foss', 'found', 'four', 'francesca', 'franck', 'frantically', 'free', 'freed', 'freeing', 'french', 'frequently', 'friend', 'friendly', 'friends', 'friendship', 'frighten', 'from', 'front', 'full', 'fulton', 'funeral', 'fungus', 'further', 'gain', 'game', 'gamekeeper', 'gangster', 'gareth', 'garlic', 'gas', 'gathering', 'gay', 'gears', 'general', 'george', 'get', 'gets', 'getting', 'giant', 'gift', 'girl', 'girls', 'given', 'gives', 'giving', 'glide', 'glo', 'gloria', 'go', 'goal', 'goalie', 'goddess', 'goes', 'going', 'goldeneye', 'good', 'gorilla', 'gorillas', 'got', 'government', 'grab', 'grabs', 'grand', 'grandchild', 'grandfather', 'grandson', 'grant', 'grave', 'graveyard', 'great', 'green', 'greenwall', 'greeted', 'grenade', 'grew', 'griffin', 'grigorovich', 'grishenko', 'ground', 'group', 'grow', 'growing', 'grown', 'guano', 'guantanamo', 'guard', 'guest', 'guests', 'guilbert', 'gun', 'gunpoint', 'habib', 'habibs', 'hack', 'hacked', 'had', 'hair', 'half', 'hallmark', 'hamm', 'hampshire', 'hand', 'handle', 'handling', 'hands', 'hannah', 'happened', 'happening', 'happens', 'happy', 'hard', 'harker', 'harming', 'harris', 'has', 'hatchet', 'hates', 'haunted', 'have', 'having', 'havoc', 'he', 'head', 'headquarters', 'heads', 'hear', 'hearing', 'heated', 'heavy', 'helicopter', 'help', 'helps', 'helsing', 'henchmen', 'her', 'heroes', 'heroism', 'hers', 'herself', 'hidden', 'hide', 'high', 'highlands', 'him', 'himalayas', 'himself', 'hired', 'hires', 'his', 'hit', 'hitch', 'hits', 'hitu', 'holding', 'holds', 'hole', 'hollywood', 'home', 'honeymoon', 'hopes', 'hospital', 'hostage', 'hostages', 'hostility', 'hotel', 'hour', 'house', 'how', 'however', 'howl', 'huck', 'huge', 'humans', 'humiliated', 'humiliating', 'hundreds', 'hunt', 'hunter', 'husband', 'hut', 'hyphenated', 'hypnotic', 'ice', 'iceburgh', 'identify', 'identity', 'if', 'ignite', 'ii', 'immediately', 'impact', 'important', 'impresses', 'in', 'inability', 'inadvertently', 'incident', 'incites', 'include', 'including', 'increased', 'indeed', 'infiltrate', 'information', 'informs', 'ingredient', 'initial', 'initially', 'initiate', 'initiating', 'injun', 'inner', 'innocent', 'inquiry', 'insensitivity', 'inside', 'insisting', 'inspired', 'instead', 'instructing', 'instructs', 'intelligence', 'intended', 'intends', 'intent', 'intentions', 'interest', 'interrogation', 'interrupted', 'intervenes', 'into', 'introduces', 'investigate', 'investigation', 'invited', 'invites', 'involved', 'involvement', 'involves', 'ione', 'irritated', 'is', 'island', 'istanbul', 'it', 'italian', 'its', 'itself', 'jack', 'jackson', 'jacob', 'james', 'jamming', 'janus', 'japan', 'jealous', 'jennifer', 'jim', 'job', 'joe', 'john', 'join', 'joins', 'joke', 'jokes', 'jokingly', 'jonas', 'jonathan', 'joshua', 'juancho', 'judy', 'jumanji', 'jungle', 'jungles', 'just', 'justify', 'kathy', 'keep', 'kevin', 'kgb', 'kicks', 'kidnap', 'kidnapped', 'kids', 'kill', 'killed', 'killing', 'kills', 'kincade', 'king', 'kiss', 'knife', 'knock', 'knocking', 'knocks', 'know', 'labor', 'lake', 'lana', 'land', 'landing', 'laptop', 'large', 'last', 'late', 'later', 'laugh', 'launch', 'lawrence', 'laws', 'leader', 'leading', 'leads', 'league', 'learn', 'learning', 'learns', 'leave', 'leaves', 'leaving', 'led', 'left', 'leg', 'lemmon', 'let', 'lets', 'level', 'liability', 'lienz', 'lies', 'life', 'lifelessness', 'lift', 'light', 'lighter', 'lightyear', 'like', 'likely', 'line', 'lion', 'lipstick', 'liquid', 'liquor', 'list', 'listen', 'little', 'lives', 'livid', 'living', 'll', 'loaded', 'local', 'locate', 'located', 'location', 'locks', 'lodged', 'london', 'long', 'longer', 'look', 'looking', 'loren', 'loses', 'losing', 'lost', 'love', 'lover', 'lowland', 'luc', 'lucky', 'lucy', 'luggage', 'lunatic', 'luxury', 'lying', 'macau', 'mackenzies', 'made', 'make', 'makes', 'making', 'malfunctions', 'mallory', 'man', 'manage', 'manages', 'maniacally', 'manner', 'mansion', 'many', 'map', 'marc', 'margaret', 'margret', 'maria', 'marines', 'marisa', 'mark', 'market', 'marks', 'marriage', 'marriages', 'married', 'marshal', 'martha', 'martin', 'marvin', 'mascot', 'master', 'masturbates', 'mate', 'mating', 'matthau', 'matthew', 'matthews', 'matty', 'max', 'mccord', 'mcdougal', 'mckissack', 'meaning', 'meanwhile', 'medic', 'medical', 'medicine', 'meet', 'meeting', 'meets', 'megan', 'melanie', 'member', 'memories', 'men', 'menopause', 'mercenary', 'meredith', 'message', 'met', 'mi6', 'might', 'mildly', 'military', 'millions', 'mimicking', 'mina', 'mind', 'minister', 'minute', 'mirror', 'misbehave', 'misbehavers', 'mishap', 'mishkin', 'misplaces', 'missile', 'missing', 'mission', 'mississippi', 'mistake', 'mistaken', 'mistakenly', 'mistakes', 'mistress', 'mobile', 'moldavian', 'molly', 'moment', 'moments', 'mon', 'monastery', 'money', 'moneypenney', 'moneypenny', 'monitor', 'monitoring', 'monkey', 'monkeys', 'monsoon', 'monster', 'monte', 'months', 'more', 'morgan', 'morning', 'moron', 'mortally', 'mosquitoes', 'most', 'mother', 'motor', 'move', 'moves', 'movie', 'moving', 'mr', 'mrs', 'much', 'muff', 'murder', 'murrell', 'must', 'mutant', 'nails', 'name', 'named', 'natalya', 'native', 'nearby', 'neck', 'need', 'neighbor', 'neighbors', 'nervously', 'nest', 'net', 'never', 'new', 'newly', 'news', 'newspaper', 'next', 'nibia', 'night', 'nights', 'nina', 'nine', 'nitrogen', 'no', 'non', 'nora', 'norman', 'not', 'nothing', 'noticed', 'notices', 'noticing', 'now', 'nuclear', 'nude', 'numerous', 'nursery', 'oath', 'obstetrician', 'obvious', 'occupied', 'odd', 'of', 'off', 'offered', 'offers', 'officer', 'offices', 'old', 'older', 'on', 'onatopp', 'once', 'one', 'only', 'onto', 'opening', 'opens', 'opera', 'operating', 'operation', 'operative', 'opposite', 'or', 'orbit', 'orchestrated', 'order', 'ordering', 'orders', 'original', 'other', 'others', 'ouda', 'ourumov', 'out', 'outcome', 'over', 'overcome', 'overnight', 'overpowers', 'overrun', 'oversees', 'overtime', 'own', 'owned', 'owner', 'page', 'pain', 'painful', 'painting', 'pair', 'pale', 'panic', 'panicking', 'panther', 'paramedics', 'paranoid', 'parents', 'park', 'parliament', 'parody', 'parrish', 'part', 'partially', 'participate', 'parting', 'parts', 'party', 'passed', 'passes', 'passion', 'patient', 'patrice', 'patricia', 'paul', 'pay', 'peace', 'peep', 'pelican', 'pelt', 'pen', 'penguins', 'penthouse', 'people', 'perform', 'performer', 'period', 'periods', 'permanently', 'personnel', 'perspectives', 'persuade', 'pet', 'peter', 'petersburg', 'phillips', 'phone', 'physical', 'piece', 'piggy', 'pill', 'pills', 'pilot', 'pink', 'pinky', 'pistol', 'pittsburgh', 'pizza', 'place', 'placed', 'places', 'placing', 'plan', 'planet', 'planned', 'planner', 'plans', 'plants', 'play', 'playing', 'pleads', 'poachers', 'pocket', 'point', 'pole', 'police', 'pollak', 'ponder', 'poorly', 'porcelain', 'position', 'possession', 'potato', 'potter', 'powered', 'powers', 'ppk', 'practical', 'praised', 'prank', 'pranks', 'pregnancies', 'pregnancy', 'pregnant', 'prepare', 'prepares', 'preparing', 'present', 'preserving', 'president', 'presses', 'pressured', 'presumed', 'prevent', 'previous', 'preys', 'priest', 'prince', 'princess', 'prior', 'problem', 'problems', 'proceed', 'proceeds', 'producer', 'professor', 'programmer', 'programming', 'projection', 'prolonging', 'promises', 'prompting', 'propane', 'properly', 'property', 'prospect', 'prostate', 'prostitute', 'protective', 'prototype', 'proval', 'prove', 'province', 'psychiatrist', 'psychological', 'public', 'pulse', 'punches', 'puncture', 'puppy', 'purchase', 'purchased', 'purpose', 'pursu', 'pursue', 'pursuers', 'pursuing', 'pushes', 'put', 'puts', 'putz', 'puzzled', 'quartermaster', 'quentin', 'quest', 'questionable', 'quickly', 'quicksand', 'quit', 'raccoon', 'radar', 'radio', 'raft', 'ragetti', 'raise', 'raised', 'rallies', 'ranger', 'raoul', 'rare', 'rather', 'rc', 're', 'ready', 'real', 'realize', 'realizes', 'realizing', 'really', 'recaptures', 'receive', 'receives', 'reckless', 'recognising', 'recognizes', 'reconcile', 'reconciled', 'records', 'recover', 'recovered', 'red', 'redecoration', 'reflection', 'reformed', 'refuses', 'regaining', 'regains', 'reignite', 'reinforcements', 'relationship', 'release', 'releases', 'relieved', 'reluctant', 'reluctantly', 'remaining', 'remains', 'rematch', 'reminds', 'remove', 'removes', 'rendition', 'renfield', 'renovation', 'repatriated', 'repeatedly', 'repel', 'replace', 'replacement', 'reprogram', 'request', 'requires', 'requiring', 'rescue', 'rescued', 'rescues', 'rescuing', 'resolve', 'respectively', 'responding', 'responds', 'responsibility', 'rest', 'restaurant', 'restored', 'restoring', 'result', 'results', 'retaliates', 'retire', 'retiring', 'retreats', 'retrieve', 'retrieves', 'return', 'returned', 'returning', 'returns', 'reunite', 'reveal', 'revealed', 'revealing', 'reveals', 'revenge', 'reverse', 'reversed', 'rex', 'rhinos', 'rid', 'ride', 'rig', 'right', 'rights', 'rigs', 'rises', 'ritual', 'river', 'road', 'roald', 'robert', 'robin', 'robinson', 'robitaille', 'rock', 'rocket', 'rockwell', 'rodriguez', 'role', 'roll', 'rolls', 'romantic', 'roof', 'room', 'rot', 'roth', 'route', 'routine', 'rover', 'row', 'rules', 'run', 'running', 'runs', 'ruptured', 'rush', 'russell', 'russian', 'sabotage', 'sacred', 'sacrificing', 'sadistic', 'safari', 'safe', 'safely', 'safety', 'saint', 'salon', 'saltwater', 'sam', 'same', 'sand', 'sandwich', 'sarah', 'sarge', 'sas', 'satellite', 'savannah', 'save', 'saved', 'saves', 'sawyer', 'saying', 'scale', 'scarf', 'scat', 'scenario', 'school', 'score', 'scores', 'scottish', 'scrapes', 'screaming', 'scud', 'search', 'searching', 'sears', 'season', 'seat', 'second', 'secret', 'secretary', 'security', 'sedated', 'seduce', 'seduces', 'seducing', 'see', 'seeing', 'seeks', 'seems', 'seen', 'sees', 'self', 'sell', 'sells', 'semen', 'sending', 'sends', 'sent', 'sentimental', 'separate', 'series', 'serve', 'servers', 'service', 'serving', 'set', 'sets', 'settle', 'settlement', 'sever', 'several', 'severe', 'severely', 'severnaya', 'seward', 'sex', 'shady', 'shanghai', 'share', 'shared', 'sharp', 'she', 'shepherd', 'sheriff', 'shields', 'shikaka', 'ship', 'shocked', 'shoe', 'shoot', 'shoots', 'shop', 'shore', 'shortly', 'shot', 'should', 'shovels', 'show', 'shower', 'shows', 'siberia', 'sid', 'side', 'sigfried', 'signed', 'signor', 'silva', 'silverback', 'simonova', 'simple', 'simultaneous', 'since', 'single', 'sister', 'site', 'situation', 'situations', 'six', 'skemp', 'skeptical', 'ski', 'skye', 'skyfall', 'slam', 'slave', 'sleep', 'sleeping', 'slept', 'slinky', 'slowed', 'smile', 'snapping', 'sneak', 'so', 'sold', 'sole', 'solicitor', 'solitude', 'some', 'someone', 'somewhere', 'son', 'song', 'sons', 'soon', 'sophia', 'sound', 'south', 'soviet', 'space', 'spain', 'spat', 'spear', 'spell', 'spends', 'spiders', 'spike', 'spirits', 'splits', 'spot', 'spots', 'spreading', 'spring', 'sprinkler', 'spy', 'stabbing', 'stabs', 'staff', 'stakes', 'stall', 'stampede', 'stand', 'standing', 'standoff', 'stands', 'stanley', 'start', 'starts', 'state', 'states', 'station', 'statue', 'stay', 'steal', 'stealing', 'steals', 'step', 'still', 'stokes', 'stolen', 'stop', 'stopped', 'stops', 'store', 'stormy', 'story', 'stows', 'strange', 'strangely', 'strapped', 'street', 'stress', 'stressed', 'strike', 'strikes', 'strongly', 'stuck', 'stumble', 'subdue', 'subjected', 'succeed', 'succeeds', 'successful', 'successfully', 'succumbs', 'such', 'sucked', 'sudden', 'suddenly', 'suggested', 'suicide', 'suitable', 'suite', 'summer', 'summoned', 'summons', 'sunlight', 'sunroof', 'support', 'supported', 'surprise', 'surround', 'survived', 'survives', 'survivor', 'suspect', 'suspected', 'suspects', 'swarm', 'sweeps', 'swing', 'switched', 'symptoms', 'syndicate', 'syringe', 'system', 'systems', 'sévérine', 'tailspin', 'take', 'taken', 'takes', 'taking', 'talk', 'tamlyn', 'tanks', 'tanner', 'tape', 'tapes', 'tarantino', 'target', 'targeted', 'tattoo', 'taunting', 'taunts', 'tavern', 'teach', 'team', 'tear', 'ted', 'television', 'tell', 'telling', 'tells', 'temple', 'ten', 'tend', 'termites', 'terms', 'terrier', 'terrorist', 'terrorists', 'than', 'that', 'thatcher', 'the', 'theft', 'their', 'them', 'themselves', 'then', 'theodore', 'there', 'thereafter', 'they', 'thing', 'things', 'thinking', 'third', 'this', 'thomas', 'though', 'threat', 'threatens', 'three', 'throat', 'through', 'throughout', 'throw', 'throwing', 'throws', 'thugs', 'thunderstorm', 'thus', 'thwarts', 'tibetan', 'ticks', 'tiger', 'tim', 'time', 'times', 'tiny', 'tipping', 'to', 'together', 'token', 'tom', 'tomei', 'tomita', 'too', 'took', 'toothbrushes', 'top', 'tortured', 'toss', 'toughest', 'tow', 'towards', 'town', 'toy', 'toys', 'traced', 'track', 'traders', 'trail', 'train', 'transform', 'translates', 'transylvania', 'trapped', 'traps', 'travel', 'travelling', 'travels', 'treasure', 'tree', 'trevelyan', 'trial', 'tribal', 'tribe', 'tribes', 'tricks', 'tried', 'tries', 'trigger', 'trio', 'trip', 'troops', 'truck', 'true', 'trust', 'truth', 'try', 'trying', 'tunnel', 'turned', 'turns', 'tv', 'twenty', 'twine', 'two', 'tying', 'tyler', 'tyrannosaur', 'ultimately', 'unable', 'unavailable', 'uncertain', 'uncover', 'undead', 'undercover', 'undergoing', 'underground', 'undo', 'uneasy', 'unexpected', 'unfortunately', 'union', 'unit', 'united', 'unknowingly', 'unknown', 'unsettled', 'unsuccessfully', 'unsure', 'until', 'unusual', 'unusually', 'up', 'upcoming', 'upon', 'uproariously', 'upset', 'use', 'used', 'useful', 'uses', 'using', 'uttering', 'vacant', 'valentin', 'value', 'vampire', 'van', 'vandalize', 'vannah', 'various', 'vatsnik', 'vengeful', 'vent', 'ventura', 'verduzco', 'version', 'vertigogo', 'via', 'vic', 'vice', 'vicious', 'village', 'vincent', 'vips', 'virgin', 'visiting', 'visits', 'vomiting', 'vonne', 'voyage', 'wachati', 'wachootoo', 'wade', 'wait', 'waiting', 'walk', 'walking', 'walls', 'walter', 'walther', 'want', 'wanted', 'wanting', 'wants', 'war', 'warning', 'warns', 'warrior', 'warts', 'was', 'washed', 'watching', 'water', 'waterfall', 'way', 'weapon', 'weapons', 'wear', 'wed', 'wedding', 'week', 'weeks', 'welcome', 'well', 'were', 'westenra', 'what', 'when', 'where', 'whether', 'which', 'while', 'whilst', 'white', 'whittle', 'who', 'whom', 'whore', 'widow', 'widowed', 'wield', 'wife', 'wild', 'wildlife', 'will', 'win', 'window', 'wings', 'wins', 'winter', 'wired', 'wishes', 'witches', 'with', 'within', 'without', 'witness', 'woman', 'women', 'won', 'wood', 'woody', 'word', 'words', 'work', 'working', 'works', 'world', 'worried', 'worries', 'worse', 'worth', 'would', 'wounded', 'wounding', 'wounds', 'wreaks', 'wrecking', 'written', 'wrong', 'xenia', 'yacht', 'year', 'years', 'yells', 'yes', 'yet', 'you', 'young', 'zebras', 'zippo', 'zukovsky']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Instantiate the vectorizer object to the vectorizer variable\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the plot column\n",
    "vectorized_data = vectorizer.fit_transform(df_plots['Plot'])\n",
    "\n",
    "# Look at the features generated\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Repeat the creation of the TfidfVectorizer, but this time, set the minimum document frequency to `2` and the maximum document frequency to `0.7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100', 'abandoned', 'about', 'above', 'access', 'accidentally', 'accomplice', 'accounts', 'accuses', 'admits', 'advised', 'afterwards', 'again', 'agent', 'agents', 'all', 'allow', 'along', 'also', 'although', 'another', 'anyone', 'appears', 'appointed', 'approached', 'argument', 'arms', 'around', 'arrested', 'arrives', 'ashes', 'asks', 'assists', 'attack', 'attacked', 'attacks', 'attempt', 'attempting', 'attempts', 'away', 'baby', 'ball', 'bank', 'bats', 'because', 'become', 'becomes', 'bed', 'been', 'before', 'begin', 'begins', 'being', 'believes', 'betraying', 'better', 'between', 'birthday', 'blow', 'bond', 'booby', 'both', 'box', 'bride', 'bring', 'brings', 'britain', 'building', 'burns', 'business', 'call', 'called', 'calls', 'came', 'can', 'captured', 'captures', 'car', 'care', 'causes', 'causing', 'caves', 'challenge', 'chance', 'chaos', 'chase', 'chases', 'child', 'children', 'chooses', 'christmas', 'church', 'cia', 'climbs', 'closed', 'coming', 'concludes', 'confronts', 'contact', 'containing', 'control', 'convinced', 'convinces', 'could', 'country', 'credits', 'crew', 'crime', 'criminal', 'culminates', 'daughter', 'day', 'days', 'dead', 'death', 'decides', 'declare', 'decline', 'deduces', 'delivers', 'department', 'desk', 'despair', 'despite', 'destroy', 'destroyed', 'destroys', 'destruction', 'devil', 'died', 'dinner', 'discovered', 'discovering', 'discovers', 'doctor', 'does', 'door', 'down', 'driving', 'drops', 'due', 'during', 'each', 'earlier', 'embark', 'empty', 'end', 'ends', 'england', 'enjoy', 'ensues', 'ensure', 'enters', 'entire', 'escape', 'escapes', 'escaping', 'eve', 'eventually', 'executive', 'expecting', 'explodes', 'explosives', 'eyed', 'failed', 'fails', 'fall', 'falling', 'falls', 'family', 'father', 'favorite', 'female', 'fictional', 'fight', 'fighting', 'fights', 'figure', 'film', 'final', 'finally', 'find', 'finding', 'finds', 'finish', 'fire', 'first', 'five', 'flee', 'follow', 'following', 'follows', 'forces', 'former', 'four', 'free', 'friend', 'friends', 'front', 'full', 'funeral', 'further', 'game', 'gears', 'get', 'gets', 'getting', 'gift', 'girl', 'gives', 'giving', 'go', 'goes', 'going', 'good', 'grabs', 'great', 'group', 'growing', 'grown', 'guard', 'gun', 'had', 'hand', 'have', 'having', 'head', 'hear', 'helicopter', 'help', 'herself', 'high', 'himself', 'hits', 'holds', 'hole', 'home', 'honeymoon', 'hospital', 'hostage', 'house', 'how', 'however', 'hunter', 'husband', 'ice', 'identity', 'if', 'inadvertently', 'including', 'instead', 'introduces', 'investigation', 'invited', 'involvement', 'island', 'its', 'itself', 'jack', 'james', 'job', 'john', 'join', 'joins', 'jungle', 'just', 'keep', 'kill', 'killed', 'killing', 'kills', 'knife', 'knock', 'lake', 'land', 'landing', 'large', 'last', 'late', 'later', 'leads', 'learn', 'learning', 'learns', 'leave', 'leaves', 'leaving', 'led', 'left', 'leg', 'let', 'life', 'light', 'local', 'london', 'long', 'longer', 'looking', 'loses', 'love', 'made', 'make', 'makes', 'making', 'man', 'manage', 'manages', 'mansion', 'marriage', 'married', 'meanwhile', 'meet', 'meeting', 'meets', 'member', 'men', 'message', 'mi6', 'missing', 'moment', 'moments', 'money', 'monkey', 'more', 'morning', 'most', 'mother', 'move', 'movie', 'moving', 'mr', 'much', 'must', 'named', 'native', 'nearby', 'need', 'neighbor', 'new', 'newly', 'news', 'next', 'night', 'no', 'not', 'notices', 'now', 'oath', 'off', 'offers', 'officer', 'once', 'only', 'opening', 'opens', 'or', 'order', 'orders', 'other', 'over', 'own', 'owner', 'parents', 'part', 'party', 'passes', 'people', 'perform', 'phone', 'place', 'plan', 'plans', 'police', 'pregnant', 'prepare', 'present', 'presumed', 'prevent', 'previous', 'prove', 'pursue', 'put', 'radio', 'raft', 'raise', 're', 'ready', 'real', 'realize', 'realizes', 'realizing', 'receives', 'reconcile', 'release', 'relieved', 'reluctantly', 'remove', 'rescue', 'resolve', 'respectively', 'rest', 'restaurant', 'restored', 'result', 'retaliates', 'retrieve', 'return', 'returns', 'revealed', 'revealing', 'reveals', 'revenge', 'ride', 'right', 'river', 'role', 'roll', 'room', 'run', 'running', 'runs', 'rush', 'sabotage', 'sam', 'same', 'sarah', 'saying', 'screaming', 'search', 'season', 'second', 'secret', 'security', 'seduce', 'seems', 'seen', 'sees', 'self', 'sell', 'sells', 'sending', 'sends', 'service', 'set', 'sets', 'sex', 'sharp', 'she', 'shoot', 'shore', 'shortly', 'shot', 'should', 'shows', 'single', 'sister', 'site', 'situation', 'six', 'slave', 'sneak', 'so', 'some', 'someone', 'son', 'soon', 'space', 'spell', 'spot', 'spring', 'stand', 'starts', 'state', 'stay', 'still', 'stolen', 'stop', 'stops', 'store', 'street', 'stress', 'strike', 'stuck', 'successful', 'successfully', 'succumbs', 'such', 'suddenly', 'suite', 'summons', 'survives', 'suspects', 'system', 'take', 'taken', 'takes', 'taking', 'team', 'television', 'tells', 'than', 'there', 'things', 'this', 'three', 'through', 'throws', 'thus', 'time', 'together', 'toss', 'towards', 'town', 'train', 'traps', 'travel', 'tribal', 'tried', 'trip', 'truck', 'true', 'trying', 'turned', 'turns', 'tying', 'ultimately', 'unable', 'until', 'unusual', 'upon', 'use', 'used', 'uses', 'van', 'wait', 'walk', 'walking', 'wanting', 'wants', 'war', 'was', 'way', 'weapons', 'wedding', 'well', 'were', 'what', 'where', 'which', 'white', 'whom', 'wife', 'will', 'window', 'women', 'word', 'work', 'working', 'world', 'worried', 'wrong', 'years', 'young']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Instantiate the vectorizer object to the vectorizer variable\n",
    "vectorizer = TfidfVectorizer(max_df=0.7, min_df=2)\n",
    "\n",
    "# Fit and transform the plot column\n",
    "vectorized_data = vectorizer.fit_transform(df_plots['Plot'])\n",
    "\n",
    "# Look at the features generated\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Create Dataframe from TF-IDFarray.  Assign the movie titles to the index and inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>access</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>accomplice</th>\n",
       "      <th>accounts</th>\n",
       "      <th>accuses</th>\n",
       "      <th>admits</th>\n",
       "      <th>...</th>\n",
       "      <th>window</th>\n",
       "      <th>women</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>worried</th>\n",
       "      <th>wrong</th>\n",
       "      <th>years</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ace Ventura: When Nature Calls</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dracula: Dead and Loving It</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049766</td>\n",
       "      <td>0.034807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Father of the Bride Part II</th>\n",
       "      <td>0.045162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051126</td>\n",
       "      <td>0.051126</td>\n",
       "      <td>0.040537</td>\n",
       "      <td>0.040537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four Rooms</th>\n",
       "      <td>0.051388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102777</td>\n",
       "      <td>0.058174</td>\n",
       "      <td>0.116348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grumpier Old Men</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jumanji</th>\n",
       "      <td>0.033913</td>\n",
       "      <td>0.060880</td>\n",
       "      <td>0.021290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033913</td>\n",
       "      <td>0.033913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060880</td>\n",
       "      <td>0.030440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sudden Death</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074920</td>\n",
       "      <td>0.059670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053558</td>\n",
       "      <td>0.053558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom and Huck</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toy Story</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waiting to Exhale</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060061</td>\n",
       "      <td>0.042008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GoldenEye</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035731</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035731</td>\n",
       "      <td>0.035731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032072</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skyfall</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     100  abandoned     about     above  \\\n",
       "Title                                                                     \n",
       "Ace Ventura: When Nature Calls  0.000000   0.000000  0.066322  0.000000   \n",
       "Dracula: Dead and Loving It     0.000000   0.049766  0.034807  0.000000   \n",
       "Father of the Bride Part II     0.045162   0.000000  0.113409  0.000000   \n",
       "Four Rooms                      0.051388   0.000000  0.000000  0.051388   \n",
       "Grumpier Old Men                0.000000   0.000000  0.026997  0.000000   \n",
       "Jumanji                         0.033913   0.060880  0.021290  0.000000   \n",
       "Sudden Death                    0.000000   0.000000  0.074920  0.059670   \n",
       "Tom and Huck                    0.000000   0.000000  0.126867  0.000000   \n",
       "Toy Story                       0.000000   0.000000  0.000000  0.000000   \n",
       "Waiting to Exhale               0.000000   0.060061  0.042008  0.000000   \n",
       "GoldenEye                       0.000000   0.000000  0.000000  0.035731   \n",
       "Skyfall                         0.000000   0.026849  0.000000  0.000000   \n",
       "\n",
       "                                  access  accidentally  accomplice  accounts  \\\n",
       "Title                                                                          \n",
       "Ace Ventura: When Nature Calls  0.000000      0.000000    0.000000  0.000000   \n",
       "Dracula: Dead and Loving It     0.000000      0.000000    0.000000  0.000000   \n",
       "Father of the Bride Part II     0.000000      0.000000    0.000000  0.000000   \n",
       "Four Rooms                      0.000000      0.058174    0.000000  0.000000   \n",
       "Grumpier Old Men                0.000000      0.000000    0.000000  0.000000   \n",
       "Jumanji                         0.000000      0.000000    0.000000  0.000000   \n",
       "Sudden Death                    0.000000      0.000000    0.000000  0.067549   \n",
       "Tom and Huck                    0.000000      0.000000    0.076257  0.000000   \n",
       "Toy Story                       0.000000      0.060080    0.000000  0.000000   \n",
       "Waiting to Exhale               0.000000      0.000000    0.000000  0.075750   \n",
       "GoldenEye                       0.040449      0.000000    0.000000  0.000000   \n",
       "Skyfall                         0.033863      0.000000    0.033863  0.000000   \n",
       "\n",
       "                                 accuses    admits  ...    window     women  \\\n",
       "Title                                               ...                       \n",
       "Ace Ventura: When Nature Calls  0.000000  0.052822  ...  0.000000  0.000000   \n",
       "Dracula: Dead and Loving It     0.000000  0.000000  ...  0.055444  0.000000   \n",
       "Father of the Bride Part II     0.000000  0.000000  ...  0.000000  0.051126   \n",
       "Four Rooms                      0.058174  0.000000  ...  0.102777  0.058174   \n",
       "Grumpier Old Men                0.000000  0.000000  ...  0.000000  0.000000   \n",
       "Jumanji                         0.000000  0.033913  ...  0.000000  0.000000   \n",
       "Sudden Death                    0.000000  0.000000  ...  0.000000  0.000000   \n",
       "Tom and Huck                    0.076257  0.000000  ...  0.000000  0.000000   \n",
       "Toy Story                       0.000000  0.000000  ...  0.053072  0.000000   \n",
       "Waiting to Exhale               0.000000  0.000000  ...  0.000000  0.000000   \n",
       "GoldenEye                       0.000000  0.035731  ...  0.000000  0.000000   \n",
       "Skyfall                         0.000000  0.000000  ...  0.000000  0.000000   \n",
       "\n",
       "                                    word      work   working     world  \\\n",
       "Title                                                                    \n",
       "Ace Ventura: When Nature Calls  0.000000  0.000000  0.052822  0.000000   \n",
       "Dracula: Dead and Loving It     0.188296  0.000000  0.000000  0.000000   \n",
       "Father of the Bride Part II     0.000000  0.051126  0.000000  0.000000   \n",
       "Four Rooms                      0.116348  0.000000  0.000000  0.000000   \n",
       "Grumpier Old Men                0.000000  0.000000  0.000000  0.000000   \n",
       "Jumanji                         0.000000  0.000000  0.033913  0.033913   \n",
       "Sudden Death                    0.000000  0.000000  0.000000  0.000000   \n",
       "Tom and Huck                    0.000000  0.000000  0.000000  0.000000   \n",
       "Toy Story                       0.000000  0.000000  0.000000  0.000000   \n",
       "Waiting to Exhale               0.000000  0.000000  0.000000  0.066914   \n",
       "GoldenEye                       0.000000  0.000000  0.035731  0.035731   \n",
       "Skyfall                         0.000000  0.033863  0.000000  0.000000   \n",
       "\n",
       "                                 worried     wrong     years     young  \n",
       "Title                                                                   \n",
       "Ace Ventura: When Nature Calls  0.000000  0.000000  0.000000  0.047412  \n",
       "Dracula: Dead and Loving It     0.000000  0.000000  0.000000  0.000000  \n",
       "Father of the Bride Part II     0.051126  0.051126  0.040537  0.040537  \n",
       "Four Rooms                      0.000000  0.058174  0.000000  0.000000  \n",
       "Grumpier Old Men                0.048681  0.000000  0.000000  0.000000  \n",
       "Jumanji                         0.000000  0.000000  0.060880  0.030440  \n",
       "Sudden Death                    0.000000  0.000000  0.053558  0.053558  \n",
       "Tom and Huck                    0.000000  0.000000  0.000000  0.000000  \n",
       "Toy Story                       0.000000  0.000000  0.000000  0.000000  \n",
       "Waiting to Exhale               0.000000  0.000000  0.000000  0.000000  \n",
       "GoldenEye                       0.000000  0.000000  0.032072  0.000000  \n",
       "Skyfall                         0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[12 rows x 563 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Instantiate the vectorizer object and transform the plot column\n",
    "vectorizer = TfidfVectorizer(max_df=0.7, min_df=2)\n",
    "vectorized_data = vectorizer.fit_transform(df_plots['Plot']) \n",
    "\n",
    "# Create Dataframe from TF-IDFarray\n",
    "tfidf_df = pd.DataFrame(vectorized_data.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Assign the movie titles to the index and inspect\n",
    "tfidf_df.index = df_plots['Title']\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Generate a matrix of all of the movie cosine similarities and store them in a DataFrame for ease of lookup. This will allow you to compare movies and find recommendations quickly and easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Title</th>\n",
       "      <th>Ace Ventura: When Nature Calls</th>\n",
       "      <th>Dracula: Dead and Loving It</th>\n",
       "      <th>Father of the Bride Part II</th>\n",
       "      <th>Four Rooms</th>\n",
       "      <th>Grumpier Old Men</th>\n",
       "      <th>Jumanji</th>\n",
       "      <th>Sudden Death</th>\n",
       "      <th>Tom and Huck</th>\n",
       "      <th>Toy Story</th>\n",
       "      <th>Waiting to Exhale</th>\n",
       "      <th>GoldenEye</th>\n",
       "      <th>Skyfall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ace Ventura: When Nature Calls</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.117079</td>\n",
       "      <td>0.198086</td>\n",
       "      <td>0.124709</td>\n",
       "      <td>0.143081</td>\n",
       "      <td>0.123459</td>\n",
       "      <td>0.201868</td>\n",
       "      <td>0.210366</td>\n",
       "      <td>0.179123</td>\n",
       "      <td>0.149005</td>\n",
       "      <td>0.128275</td>\n",
       "      <td>0.100175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dracula: Dead and Loving It</th>\n",
       "      <td>0.117079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136838</td>\n",
       "      <td>0.192302</td>\n",
       "      <td>0.061615</td>\n",
       "      <td>0.211044</td>\n",
       "      <td>0.155436</td>\n",
       "      <td>0.141746</td>\n",
       "      <td>0.100207</td>\n",
       "      <td>0.079803</td>\n",
       "      <td>0.086261</td>\n",
       "      <td>0.092680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Father of the Bride Part II</th>\n",
       "      <td>0.198086</td>\n",
       "      <td>0.136838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.147338</td>\n",
       "      <td>0.164555</td>\n",
       "      <td>0.146734</td>\n",
       "      <td>0.149621</td>\n",
       "      <td>0.183656</td>\n",
       "      <td>0.187719</td>\n",
       "      <td>0.180614</td>\n",
       "      <td>0.055370</td>\n",
       "      <td>0.079153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four Rooms</th>\n",
       "      <td>0.124709</td>\n",
       "      <td>0.192302</td>\n",
       "      <td>0.147338</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.112788</td>\n",
       "      <td>0.162496</td>\n",
       "      <td>0.170015</td>\n",
       "      <td>0.131722</td>\n",
       "      <td>0.087361</td>\n",
       "      <td>0.116039</td>\n",
       "      <td>0.028097</td>\n",
       "      <td>0.049336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grumpier Old Men</th>\n",
       "      <td>0.143081</td>\n",
       "      <td>0.061615</td>\n",
       "      <td>0.164555</td>\n",
       "      <td>0.112788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088563</td>\n",
       "      <td>0.086428</td>\n",
       "      <td>0.107119</td>\n",
       "      <td>0.121622</td>\n",
       "      <td>0.177354</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>0.038290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jumanji</th>\n",
       "      <td>0.123459</td>\n",
       "      <td>0.211044</td>\n",
       "      <td>0.146734</td>\n",
       "      <td>0.162496</td>\n",
       "      <td>0.088563</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.294398</td>\n",
       "      <td>0.129235</td>\n",
       "      <td>0.091685</td>\n",
       "      <td>0.096105</td>\n",
       "      <td>0.048537</td>\n",
       "      <td>0.059096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sudden Death</th>\n",
       "      <td>0.201868</td>\n",
       "      <td>0.155436</td>\n",
       "      <td>0.149621</td>\n",
       "      <td>0.170015</td>\n",
       "      <td>0.086428</td>\n",
       "      <td>0.294398</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.172419</td>\n",
       "      <td>0.207805</td>\n",
       "      <td>0.126252</td>\n",
       "      <td>0.160423</td>\n",
       "      <td>0.115924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom and Huck</th>\n",
       "      <td>0.210366</td>\n",
       "      <td>0.141746</td>\n",
       "      <td>0.183656</td>\n",
       "      <td>0.131722</td>\n",
       "      <td>0.107119</td>\n",
       "      <td>0.129235</td>\n",
       "      <td>0.172419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.135127</td>\n",
       "      <td>0.149253</td>\n",
       "      <td>0.063123</td>\n",
       "      <td>0.078567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toy Story</th>\n",
       "      <td>0.179123</td>\n",
       "      <td>0.100207</td>\n",
       "      <td>0.187719</td>\n",
       "      <td>0.087361</td>\n",
       "      <td>0.121622</td>\n",
       "      <td>0.091685</td>\n",
       "      <td>0.207805</td>\n",
       "      <td>0.135127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141953</td>\n",
       "      <td>0.079459</td>\n",
       "      <td>0.068524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waiting to Exhale</th>\n",
       "      <td>0.149005</td>\n",
       "      <td>0.079803</td>\n",
       "      <td>0.180614</td>\n",
       "      <td>0.116039</td>\n",
       "      <td>0.177354</td>\n",
       "      <td>0.096105</td>\n",
       "      <td>0.126252</td>\n",
       "      <td>0.149253</td>\n",
       "      <td>0.141953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.036250</td>\n",
       "      <td>0.071050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GoldenEye</th>\n",
       "      <td>0.128275</td>\n",
       "      <td>0.086261</td>\n",
       "      <td>0.055370</td>\n",
       "      <td>0.028097</td>\n",
       "      <td>0.037226</td>\n",
       "      <td>0.048537</td>\n",
       "      <td>0.160423</td>\n",
       "      <td>0.063123</td>\n",
       "      <td>0.079459</td>\n",
       "      <td>0.036250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skyfall</th>\n",
       "      <td>0.100175</td>\n",
       "      <td>0.092680</td>\n",
       "      <td>0.079153</td>\n",
       "      <td>0.049336</td>\n",
       "      <td>0.038290</td>\n",
       "      <td>0.059096</td>\n",
       "      <td>0.115924</td>\n",
       "      <td>0.078567</td>\n",
       "      <td>0.068524</td>\n",
       "      <td>0.071050</td>\n",
       "      <td>0.764839</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Title                           Ace Ventura: When Nature Calls  \\\n",
       "Title                                                            \n",
       "Ace Ventura: When Nature Calls                        1.000000   \n",
       "Dracula: Dead and Loving It                           0.117079   \n",
       "Father of the Bride Part II                           0.198086   \n",
       "Four Rooms                                            0.124709   \n",
       "Grumpier Old Men                                      0.143081   \n",
       "Jumanji                                               0.123459   \n",
       "Sudden Death                                          0.201868   \n",
       "Tom and Huck                                          0.210366   \n",
       "Toy Story                                             0.179123   \n",
       "Waiting to Exhale                                     0.149005   \n",
       "GoldenEye                                             0.128275   \n",
       "Skyfall                                               0.100175   \n",
       "\n",
       "Title                           Dracula: Dead and Loving It  \\\n",
       "Title                                                         \n",
       "Ace Ventura: When Nature Calls                     0.117079   \n",
       "Dracula: Dead and Loving It                        1.000000   \n",
       "Father of the Bride Part II                        0.136838   \n",
       "Four Rooms                                         0.192302   \n",
       "Grumpier Old Men                                   0.061615   \n",
       "Jumanji                                            0.211044   \n",
       "Sudden Death                                       0.155436   \n",
       "Tom and Huck                                       0.141746   \n",
       "Toy Story                                          0.100207   \n",
       "Waiting to Exhale                                  0.079803   \n",
       "GoldenEye                                          0.086261   \n",
       "Skyfall                                            0.092680   \n",
       "\n",
       "Title                           Father of the Bride Part II  Four Rooms  \\\n",
       "Title                                                                     \n",
       "Ace Ventura: When Nature Calls                     0.198086    0.124709   \n",
       "Dracula: Dead and Loving It                        0.136838    0.192302   \n",
       "Father of the Bride Part II                        1.000000    0.147338   \n",
       "Four Rooms                                         0.147338    1.000000   \n",
       "Grumpier Old Men                                   0.164555    0.112788   \n",
       "Jumanji                                            0.146734    0.162496   \n",
       "Sudden Death                                       0.149621    0.170015   \n",
       "Tom and Huck                                       0.183656    0.131722   \n",
       "Toy Story                                          0.187719    0.087361   \n",
       "Waiting to Exhale                                  0.180614    0.116039   \n",
       "GoldenEye                                          0.055370    0.028097   \n",
       "Skyfall                                            0.079153    0.049336   \n",
       "\n",
       "Title                           Grumpier Old Men   Jumanji  Sudden Death  \\\n",
       "Title                                                                      \n",
       "Ace Ventura: When Nature Calls          0.143081  0.123459      0.201868   \n",
       "Dracula: Dead and Loving It             0.061615  0.211044      0.155436   \n",
       "Father of the Bride Part II             0.164555  0.146734      0.149621   \n",
       "Four Rooms                              0.112788  0.162496      0.170015   \n",
       "Grumpier Old Men                        1.000000  0.088563      0.086428   \n",
       "Jumanji                                 0.088563  1.000000      0.294398   \n",
       "Sudden Death                            0.086428  0.294398      1.000000   \n",
       "Tom and Huck                            0.107119  0.129235      0.172419   \n",
       "Toy Story                               0.121622  0.091685      0.207805   \n",
       "Waiting to Exhale                       0.177354  0.096105      0.126252   \n",
       "GoldenEye                               0.037226  0.048537      0.160423   \n",
       "Skyfall                                 0.038290  0.059096      0.115924   \n",
       "\n",
       "Title                           Tom and Huck  Toy Story  Waiting to Exhale  \\\n",
       "Title                                                                        \n",
       "Ace Ventura: When Nature Calls      0.210366   0.179123           0.149005   \n",
       "Dracula: Dead and Loving It         0.141746   0.100207           0.079803   \n",
       "Father of the Bride Part II         0.183656   0.187719           0.180614   \n",
       "Four Rooms                          0.131722   0.087361           0.116039   \n",
       "Grumpier Old Men                    0.107119   0.121622           0.177354   \n",
       "Jumanji                             0.129235   0.091685           0.096105   \n",
       "Sudden Death                        0.172419   0.207805           0.126252   \n",
       "Tom and Huck                        1.000000   0.135127           0.149253   \n",
       "Toy Story                           0.135127   1.000000           0.141953   \n",
       "Waiting to Exhale                   0.149253   0.141953           1.000000   \n",
       "GoldenEye                           0.063123   0.079459           0.036250   \n",
       "Skyfall                             0.078567   0.068524           0.071050   \n",
       "\n",
       "Title                           GoldenEye   Skyfall  \n",
       "Title                                                \n",
       "Ace Ventura: When Nature Calls   0.128275  0.100175  \n",
       "Dracula: Dead and Loving It      0.086261  0.092680  \n",
       "Father of the Bride Part II      0.055370  0.079153  \n",
       "Four Rooms                       0.028097  0.049336  \n",
       "Grumpier Old Men                 0.037226  0.038290  \n",
       "Jumanji                          0.048537  0.059096  \n",
       "Sudden Death                     0.160423  0.115924  \n",
       "Tom and Huck                     0.063123  0.078567  \n",
       "Toy Story                        0.079459  0.068524  \n",
       "Waiting to Exhale                0.036250  0.071050  \n",
       "GoldenEye                        1.000000  0.764839  \n",
       "Skyfall                          0.764839  1.000000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import cosine_similarity measure\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Create the array of cosine similarity values\n",
    "cosine_similarity_array = cosine_similarity(tfidf_df)\n",
    "\n",
    "# Wrap the array in a pandas DataFrame\n",
    "cosine_similarity_df = pd.DataFrame(cosine_similarity_array, index=tfidf_df.index, columns=tfidf_df.index)\n",
    "\n",
    "# Print the top 5 rows of the DataFrame\n",
    "cosine_similarity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**  we pre-calculated the similarity ratings between all movies in the dataset based on their plots transformed by TF-IDF. Now put these similarity ratings in a DataFrame for ease of use. Then use this new DataFrame to suggest a movie recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\n",
       "Skyfall                           1.000000\n",
       "GoldenEye                         0.764839\n",
       "Sudden Death                      0.115924\n",
       "Ace Ventura: When Nature Calls    0.100175\n",
       "Dracula: Dead and Loving It       0.092680\n",
       "Father of the Bride Part II       0.079153\n",
       "Tom and Huck                      0.078567\n",
       "Waiting to Exhale                 0.071050\n",
       "Toy Story                         0.068524\n",
       "Jumanji                           0.059096\n",
       "Four Rooms                        0.049336\n",
       "Grumpier Old Men                  0.038290\n",
       "Name: Skyfall, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the values for the movie Rio\n",
    "cosine_similarity_series = cosine_similarity_df.loc['Skyfall']\n",
    "\n",
    "# Sort these values highest to lowest\n",
    "ordered_similarities = cosine_similarity_series.sort_values(ascending=False)\n",
    "\n",
    "# Print the results\n",
    "ordered_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "Based on your analysis, which movie in the dataset is most similar to `Skyfall`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User profile recommendations\n",
    "### Item to item recommendations\n",
    "\n",
    "This has many uses such as suggesting obscure books that are similar to your favorite, proposing the next movie to watch that is like the one you just finished, or even finding alternative options when items are out of stock.\n",
    "<img src=\"image/36.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "`tfidf_summary_df` :\n",
    "<img src=\"image/37.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Extract the user data\n",
    "```python\n",
    "list_of_books_read = ['The Hobbit', 'Foundation', 'Nudge']\n",
    "user_books = tfidf_summary_df.reindex(list_of_books_read)\n",
    "print(user_books)\n",
    "```\n",
    "<img src=\"image/38.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Build the user profile\n",
    "```python\n",
    "user_prof = user_books.mean()\n",
    "print(user_prof)\n",
    "```\n",
    "<img src=\"image/39.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "```python\n",
    "print(user_prof.values.reshape(1,-1))\n",
    "```\n",
    "answer:\n",
    "`[0.376667, .480000, 0.426667, 0.256667, ...]`\n",
    "\n",
    "### Finding recommendations for a user\n",
    "```python\n",
    "# Create a subset of only the non read books\n",
    "non_user_books = tfidf_summary_df.drop(list_of_books_read, axis=0)\n",
    "# Calculate the cosine similarity between all rows\n",
    "user_prof_similarities = cosine_similarity(user_prof.values.reshape(1, -1),\n",
    "non_user_books)\n",
    "# Wrap in a DataFrame for ease of use\n",
    "user_prof_similarities_df = pd.DataFrame(user_prof_similarities.T,\n",
    "index=tfidf_summary_df.index,\n",
    "columns=[\"similarity_score\"])\n",
    "```\n",
    "### Getting the top recommendations\n",
    "```python\n",
    "sorted_similarity_df = user_prof_similarities.sort_values(by=\"similarity_score\",\n",
    "ascending=False)\n",
    "print(sorted_similarity_df)\n",
    "```\n",
    "<img src=\"image/40.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "<img src=\"https://i1.wp.com/www.firstplaceforhealth.com/wp-content/uploads/2020/03/train-your-brain-gif-2.gif?fit=1200%2C904&ssl=1\" width=\"300\" height=\"100\">\n",
    "\n",
    "**Exercise:** Work through how one could create recommendations based on a user and all the items they liked as opposed to a singular item. You will first generate a profile for a user by aggregating all of the movies they have previously enjoyed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>access</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>accomplice</th>\n",
       "      <th>accounts</th>\n",
       "      <th>accuses</th>\n",
       "      <th>admits</th>\n",
       "      <th>...</th>\n",
       "      <th>window</th>\n",
       "      <th>women</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>working</th>\n",
       "      <th>world</th>\n",
       "      <th>worried</th>\n",
       "      <th>wrong</th>\n",
       "      <th>years</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Skyfall</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026849</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.033863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jumanji</th>\n",
       "      <td>0.033913</td>\n",
       "      <td>0.060880</td>\n",
       "      <td>0.02129</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033913</td>\n",
       "      <td>0.033913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060880</td>\n",
       "      <td>0.030440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sudden Death</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.07492</td>\n",
       "      <td>0.05967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053558</td>\n",
       "      <td>0.053558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   100  abandoned    about    above    access  accidentally  \\\n",
       "Title                                                                         \n",
       "Skyfall       0.000000   0.026849  0.00000  0.00000  0.033863           0.0   \n",
       "Jumanji       0.033913   0.060880  0.02129  0.00000  0.000000           0.0   \n",
       "Sudden Death  0.000000   0.000000  0.07492  0.05967  0.000000           0.0   \n",
       "\n",
       "              accomplice  accounts  accuses    admits  ...  window  women  \\\n",
       "Title                                                  ...                  \n",
       "Skyfall         0.033863  0.000000      0.0  0.000000  ...     0.0    0.0   \n",
       "Jumanji         0.000000  0.000000      0.0  0.033913  ...     0.0    0.0   \n",
       "Sudden Death    0.000000  0.067549      0.0  0.000000  ...     0.0    0.0   \n",
       "\n",
       "              word      work   working     world  worried  wrong     years  \\\n",
       "Title                                                                        \n",
       "Skyfall        0.0  0.033863  0.000000  0.000000      0.0    0.0  0.000000   \n",
       "Jumanji        0.0  0.000000  0.033913  0.033913      0.0    0.0  0.060880   \n",
       "Sudden Death   0.0  0.000000  0.000000  0.000000      0.0    0.0  0.053558   \n",
       "\n",
       "                 young  \n",
       "Title                   \n",
       "Skyfall       0.000000  \n",
       "Jumanji       0.030440  \n",
       "Sudden Death  0.053558  \n",
       "\n",
       "[3 rows x 563 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_movies_enjoyed = ['Skyfall', 'Jumanji', 'Sudden Death']\n",
    "\n",
    "# Create a subset of only the movies the user has enjoyed\n",
    "movies_enjoyed_df = tfidf_df.reindex(list_of_movies_enjoyed)\n",
    "\n",
    "# Inspect the DataFrame\n",
    "movies_enjoyed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100          0.011304\n",
      "abandoned    0.029243\n",
      "about        0.032070\n",
      "above        0.019890\n",
      "access       0.011288\n",
      "               ...   \n",
      "world        0.011304\n",
      "worried      0.000000\n",
      "wrong        0.000000\n",
      "years        0.038146\n",
      "young        0.027999\n",
      "Length: 563, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Generate the user profile by finding the average scores of movies they enjoyed\n",
    "user_prof = movies_enjoyed_df.mean()\n",
    "\n",
    "# Inspect the results\n",
    "print(user_prof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Find the subset of `tfidf_df` that does not include movies in `list_of_movies_enjoyed` and assign it to `tfidf_subset_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Find subset of tfidf_df that does not include movies in list_of_movies_enjoyed\n",
    "tfidf_subset_df = tfidf_df.drop(list_of_movies_enjoyed, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine_similarity and wrap it in a DataFrame\n",
    "similarity_array = cosine_similarity(user_prof.values.reshape(1, -1), tfidf_subset_df)\n",
    "similarity_df = pd.DataFrame(similarity_array.T, index=tfidf_subset_df.index, columns=[\"similarity_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                similarity_score\n",
      "Title                                           \n",
      "GoldenEye                               0.490665\n",
      "Dracula: Dead and Loving It             0.231356\n",
      "Ace Ventura: When Nature Calls          0.214397\n",
      "Four Rooms                              0.192400\n",
      "Tom and Huck                            0.191581\n"
     ]
    }
   ],
   "source": [
    "# Sort the values from high to low by the values in the similarity_score\n",
    "sorted_similarity_df = similarity_df.sort_values(by=\"similarity_score\", ascending=False)\n",
    "\n",
    "# Inspect the most similar to the user preferences\n",
    "print(sorted_similarity_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/c3.PNG\" width=\"1000\" height=\"100\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering\n",
    "Collaborative filtering is the name given to the prediction, or filtering, of items that might interest a user based on the preferences of similar users. It works around the premise that person A has similar tastes to person B and C.\n",
    "and both person B and C also like a certain item,\n",
    "then it is likely that person A would also like that new item.\n",
    "\n",
    "<img src=\"image/43.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Finding similar users\n",
    "\n",
    "<img src=\"image/45.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Working with real data\n",
    "`user_ratings` DataFrame:\n",
    "<img src=\"image/46.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Pivoting our data\n",
    "\n",
    "```python\n",
    "user_ratings_pivot = user_ratings.pivot(index='User',\n",
    "columns='Book',\n",
    "values='Rating')\n",
    "print(user_ratings_pivot)\n",
    "```\n",
    "<img src=\"image/47.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Data sparsity\n",
    "\n",
    "```python\n",
    "print(user_ratings_pivot.dropna())\n",
    "```\n",
    "<img src=\"image/48.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Filling the missing values\n",
    "For example the second user here. They loved Catcher in the Rye, and enjoyed Fifty Shades of Grey, but have not rated The Great Gatsby. If we were to fill this NaN with a 0, we would be incorrectly implying they greatly disliked the book compared to the others, which we can't say for sure.\n",
    "```python\n",
    "print(user_ratings_pivot[\"User_651\"].fillna(0))\n",
    "```\n",
    "<img src=\"image/49.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "\n",
    "One alternative is to center each user's ratings around 0 by deducting the row average and then fill in the missing values with 0. This means the missing data is replaced with neutral scores.\n",
    "<img src=\"image/50.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "\n",
    "```python\n",
    "avg_ratings = user_ratings_pivot.mean(axis=1)\n",
    "user_ratings_pivot = user_ratings_pivot.sub(avg_ratings, axis=0)\n",
    "print(user_ratings_pivot)\n",
    "```\n",
    "<img src=\"image/51.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "```python\n",
    "user_ratings_pivot.fillna(0)\n",
    "```\n",
    "<img src=\"image/52.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "\n",
    "<img src=\"https://i1.wp.com/www.firstplaceforhealth.com/wp-content/uploads/2020/03/train-your-brain-gif-2.gif?fit=1200%2C904&ssl=1\" width=\"300\" height=\"100\">\n",
    "\n",
    "**Exercise:** Compare movies and see whether they have received similar reviewing patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_15</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_17</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>user_506</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Interstellar (2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>user_397</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Eat Drink Man Woman (Yin shi nan nu) (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>user_556</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Aladdin (1992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>user_175</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Secret Garden, The (1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>user_578</td>\n",
       "      <td>4.0</td>\n",
       "      <td>First Wives Club, The (1996)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  rating                                        title\n",
       "0      user_1     4.0                             Toy Story (1995)\n",
       "1      user_5     4.0                             Toy Story (1995)\n",
       "2      user_7     4.5                             Toy Story (1995)\n",
       "3     user_15     2.5                             Toy Story (1995)\n",
       "4     user_17     4.5                             Toy Story (1995)\n",
       "..        ...     ...                                          ...\n",
       "605  user_506     5.0                          Interstellar (2014)\n",
       "606  user_397     4.5  Eat Drink Man Woman (Yin shi nan nu) (1994)\n",
       "607  user_556     5.0                               Aladdin (1992)\n",
       "608  user_175     3.5                    Secret Garden, The (1993)\n",
       "609  user_578     4.0                 First Wives Club, The (1996)\n",
       "\n",
       "[610 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ratings=pd.read_csv('user_ratings1.csv')\n",
    "user_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>title</th>\n",
       "      <th>13th Warrior, The (1999)</th>\n",
       "      <th>Abyss, The (1989)</th>\n",
       "      <th>Aladdin (1992)</th>\n",
       "      <th>Alice in Wonderland (1951)</th>\n",
       "      <th>Alien (1979)</th>\n",
       "      <th>Apocalypse Now (1979)</th>\n",
       "      <th>Austin Powers: International Man of Mystery (1997)</th>\n",
       "      <th>Bambi (1942)</th>\n",
       "      <th>Basic Instinct (1992)</th>\n",
       "      <th>Batman (1989)</th>\n",
       "      <th>...</th>\n",
       "      <th>Three Musketeers, The (1993)</th>\n",
       "      <th>Tommy Boy (1995)</th>\n",
       "      <th>Toy Story (1995)</th>\n",
       "      <th>Toys (1992)</th>\n",
       "      <th>Usual Suspects, The (1995)</th>\n",
       "      <th>Wild Things (1998)</th>\n",
       "      <th>Willow (1988)</th>\n",
       "      <th>Willy Wonka &amp; the Chocolate Factory (1971)</th>\n",
       "      <th>X-Men (2000)</th>\n",
       "      <th>Zombieland (2009)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_100</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_101</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_102</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_95</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_98</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "title     13th Warrior, The (1999)  Abyss, The (1989)  Aladdin (1992)  \\\n",
       "userId                                                                  \n",
       "user_1                         NaN                NaN             NaN   \n",
       "user_10                        NaN                NaN             NaN   \n",
       "user_100                       NaN                NaN             NaN   \n",
       "user_101                       NaN                NaN             NaN   \n",
       "user_102                       NaN                NaN             NaN   \n",
       "...                            ...                ...             ...   \n",
       "user_95                        NaN                NaN             NaN   \n",
       "user_96                        NaN                NaN             NaN   \n",
       "user_97                        NaN                NaN             NaN   \n",
       "user_98                        NaN                NaN             NaN   \n",
       "user_99                        NaN                NaN             NaN   \n",
       "\n",
       "title     Alice in Wonderland (1951)  Alien (1979)  Apocalypse Now (1979)  \\\n",
       "userId                                                                      \n",
       "user_1                           NaN           NaN                    NaN   \n",
       "user_10                          NaN           NaN                    NaN   \n",
       "user_100                         NaN           NaN                    NaN   \n",
       "user_101                         NaN           NaN                    NaN   \n",
       "user_102                         NaN           NaN                    NaN   \n",
       "...                              ...           ...                    ...   \n",
       "user_95                          NaN           NaN                    NaN   \n",
       "user_96                          NaN           NaN                    NaN   \n",
       "user_97                          NaN           NaN                    NaN   \n",
       "user_98                          NaN           NaN                    NaN   \n",
       "user_99                          NaN           NaN                    NaN   \n",
       "\n",
       "title     Austin Powers: International Man of Mystery (1997)  Bambi (1942)  \\\n",
       "userId                                                                       \n",
       "user_1                                                  NaN            NaN   \n",
       "user_10                                                 NaN            NaN   \n",
       "user_100                                                NaN            NaN   \n",
       "user_101                                                NaN            NaN   \n",
       "user_102                                                NaN            NaN   \n",
       "...                                                     ...            ...   \n",
       "user_95                                                 NaN            NaN   \n",
       "user_96                                                 NaN            NaN   \n",
       "user_97                                                 NaN            NaN   \n",
       "user_98                                                 NaN            NaN   \n",
       "user_99                                                 NaN            NaN   \n",
       "\n",
       "title     Basic Instinct (1992)  Batman (1989)  ...  \\\n",
       "userId                                          ...   \n",
       "user_1                      NaN            NaN  ...   \n",
       "user_10                     NaN            NaN  ...   \n",
       "user_100                    NaN            NaN  ...   \n",
       "user_101                    NaN            NaN  ...   \n",
       "user_102                    NaN            NaN  ...   \n",
       "...                         ...            ...  ...   \n",
       "user_95                     NaN            NaN  ...   \n",
       "user_96                     NaN            NaN  ...   \n",
       "user_97                     NaN            NaN  ...   \n",
       "user_98                     NaN            NaN  ...   \n",
       "user_99                     NaN            NaN  ...   \n",
       "\n",
       "title     Three Musketeers, The (1993)  Tommy Boy (1995)  Toy Story (1995)  \\\n",
       "userId                                                                       \n",
       "user_1                             NaN               NaN               4.0   \n",
       "user_10                            NaN               NaN               NaN   \n",
       "user_100                           NaN               NaN               NaN   \n",
       "user_101                           NaN               NaN               NaN   \n",
       "user_102                           NaN               NaN               NaN   \n",
       "...                                ...               ...               ...   \n",
       "user_95                            NaN               NaN               NaN   \n",
       "user_96                            NaN               NaN               5.0   \n",
       "user_97                            NaN               NaN               NaN   \n",
       "user_98                            NaN               NaN               4.5   \n",
       "user_99                            NaN               NaN               NaN   \n",
       "\n",
       "title     Toys (1992)  Usual Suspects, The (1995)  Wild Things (1998)  \\\n",
       "userId                                                                  \n",
       "user_1            NaN                         NaN                 NaN   \n",
       "user_10           NaN                         NaN                 NaN   \n",
       "user_100          NaN                         NaN                 NaN   \n",
       "user_101          NaN                         NaN                 NaN   \n",
       "user_102          NaN                         NaN                 NaN   \n",
       "...               ...                         ...                 ...   \n",
       "user_95           NaN                         NaN                 NaN   \n",
       "user_96           NaN                         NaN                 NaN   \n",
       "user_97           NaN                         NaN                 NaN   \n",
       "user_98           NaN                         NaN                 NaN   \n",
       "user_99           NaN                         NaN                 NaN   \n",
       "\n",
       "title     Willow (1988)  Willy Wonka & the Chocolate Factory (1971)  \\\n",
       "userId                                                                \n",
       "user_1              NaN                                         NaN   \n",
       "user_10             NaN                                         NaN   \n",
       "user_100            NaN                                         NaN   \n",
       "user_101            NaN                                         NaN   \n",
       "user_102            NaN                                         NaN   \n",
       "...                 ...                                         ...   \n",
       "user_95             NaN                                         NaN   \n",
       "user_96             NaN                                         NaN   \n",
       "user_97             NaN                                         NaN   \n",
       "user_98             NaN                                         NaN   \n",
       "user_99             NaN                                         NaN   \n",
       "\n",
       "title     X-Men (2000)  Zombieland (2009)  \n",
       "userId                                     \n",
       "user_1             NaN                NaN  \n",
       "user_10            NaN                NaN  \n",
       "user_100           NaN                NaN  \n",
       "user_101           NaN                NaN  \n",
       "user_102           NaN                NaN  \n",
       "...                ...                ...  \n",
       "user_95            NaN                NaN  \n",
       "user_96            NaN                NaN  \n",
       "user_97            NaN                NaN  \n",
       "user_98            NaN                NaN  \n",
       "user_99            NaN                NaN  \n",
       "\n",
       "[610 rows x 75 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ratings_df = user_ratings.pivot(index='userId',\n",
    "columns='title',\n",
    "values='rating')\n",
    "user_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "user_ratings_df_imputed=imp.fit_transform(user_ratings_df)\n",
    "user_ratings_df_imputed=pd.DataFrame(user_ratings_df_imputed,index=user_ratings_df.index, columns=user_ratings_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>title</th>\n",
       "      <th>13th Warrior, The (1999)</th>\n",
       "      <th>Abyss, The (1989)</th>\n",
       "      <th>Aladdin (1992)</th>\n",
       "      <th>Alice in Wonderland (1951)</th>\n",
       "      <th>Alien (1979)</th>\n",
       "      <th>Apocalypse Now (1979)</th>\n",
       "      <th>Austin Powers: International Man of Mystery (1997)</th>\n",
       "      <th>Bambi (1942)</th>\n",
       "      <th>Basic Instinct (1992)</th>\n",
       "      <th>Batman (1989)</th>\n",
       "      <th>...</th>\n",
       "      <th>Three Musketeers, The (1993)</th>\n",
       "      <th>Tommy Boy (1995)</th>\n",
       "      <th>Toy Story (1995)</th>\n",
       "      <th>Toys (1992)</th>\n",
       "      <th>Usual Suspects, The (1995)</th>\n",
       "      <th>Wild Things (1998)</th>\n",
       "      <th>Willow (1988)</th>\n",
       "      <th>Willy Wonka &amp; the Chocolate Factory (1971)</th>\n",
       "      <th>X-Men (2000)</th>\n",
       "      <th>Zombieland (2009)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_1</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.21875</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_10</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.92093</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.21875</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_100</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.92093</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.21875</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_101</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.92093</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.21875</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_102</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.92093</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.21875</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_95</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.92093</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.21875</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_96</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.21875</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_97</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.92093</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.21875</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_98</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.50000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.21875</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_99</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.92093</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.21875</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "title     13th Warrior, The (1999)  Abyss, The (1989)  Aladdin (1992)  \\\n",
       "userId                                                                  \n",
       "user_1                         4.5                3.0             5.0   \n",
       "user_10                        4.5                3.0             5.0   \n",
       "user_100                       4.5                3.0             5.0   \n",
       "user_101                       4.5                3.0             5.0   \n",
       "user_102                       4.5                3.0             5.0   \n",
       "...                            ...                ...             ...   \n",
       "user_95                        4.5                3.0             5.0   \n",
       "user_96                        4.5                3.0             5.0   \n",
       "user_97                        4.5                3.0             5.0   \n",
       "user_98                        4.5                3.0             5.0   \n",
       "user_99                        4.5                3.0             5.0   \n",
       "\n",
       "title     Alice in Wonderland (1951)  Alien (1979)  Apocalypse Now (1979)  \\\n",
       "userId                                                                      \n",
       "user_1                           4.0          4.75                    2.5   \n",
       "user_10                          4.0          4.75                    2.5   \n",
       "user_100                         4.0          4.75                    2.5   \n",
       "user_101                         4.0          4.75                    2.5   \n",
       "user_102                         4.0          4.75                    2.5   \n",
       "...                              ...           ...                    ...   \n",
       "user_95                          4.0          4.75                    2.5   \n",
       "user_96                          4.0          4.75                    2.5   \n",
       "user_97                          4.0          4.75                    2.5   \n",
       "user_98                          4.0          4.75                    2.5   \n",
       "user_99                          4.0          4.75                    2.5   \n",
       "\n",
       "title     Austin Powers: International Man of Mystery (1997)  Bambi (1942)  \\\n",
       "userId                                                                       \n",
       "user_1                                                  3.0            3.5   \n",
       "user_10                                                 3.0            3.5   \n",
       "user_100                                                3.0            3.5   \n",
       "user_101                                                3.0            3.5   \n",
       "user_102                                                3.0            3.5   \n",
       "...                                                     ...            ...   \n",
       "user_95                                                 3.0            3.5   \n",
       "user_96                                                 3.0            3.5   \n",
       "user_97                                                 3.0            3.5   \n",
       "user_98                                                 3.0            3.5   \n",
       "user_99                                                 3.0            3.5   \n",
       "\n",
       "title     Basic Instinct (1992)  Batman (1989)  ...  \\\n",
       "userId                                          ...   \n",
       "user_1                     2.25            4.0  ...   \n",
       "user_10                    2.25            4.0  ...   \n",
       "user_100                   2.25            4.0  ...   \n",
       "user_101                   2.25            4.0  ...   \n",
       "user_102                   2.25            4.0  ...   \n",
       "...                         ...            ...  ...   \n",
       "user_95                    2.25            4.0  ...   \n",
       "user_96                    2.25            4.0  ...   \n",
       "user_97                    2.25            4.0  ...   \n",
       "user_98                    2.25            4.0  ...   \n",
       "user_99                    2.25            4.0  ...   \n",
       "\n",
       "title     Three Musketeers, The (1993)  Tommy Boy (1995)  Toy Story (1995)  \\\n",
       "userId                                                                       \n",
       "user_1                             2.0               4.0           4.00000   \n",
       "user_10                            2.0               4.0           3.92093   \n",
       "user_100                           2.0               4.0           3.92093   \n",
       "user_101                           2.0               4.0           3.92093   \n",
       "user_102                           2.0               4.0           3.92093   \n",
       "...                                ...               ...               ...   \n",
       "user_95                            2.0               4.0           3.92093   \n",
       "user_96                            2.0               4.0           5.00000   \n",
       "user_97                            2.0               4.0           3.92093   \n",
       "user_98                            2.0               4.0           4.50000   \n",
       "user_99                            2.0               4.0           3.92093   \n",
       "\n",
       "title     Toys (1992)  Usual Suspects, The (1995)  Wild Things (1998)  \\\n",
       "userId                                                                  \n",
       "user_1            2.5                     4.21875                 0.5   \n",
       "user_10           2.5                     4.21875                 0.5   \n",
       "user_100          2.5                     4.21875                 0.5   \n",
       "user_101          2.5                     4.21875                 0.5   \n",
       "user_102          2.5                     4.21875                 0.5   \n",
       "...               ...                         ...                 ...   \n",
       "user_95           2.5                     4.21875                 0.5   \n",
       "user_96           2.5                     4.21875                 0.5   \n",
       "user_97           2.5                     4.21875                 0.5   \n",
       "user_98           2.5                     4.21875                 0.5   \n",
       "user_99           2.5                     4.21875                 0.5   \n",
       "\n",
       "title     Willow (1988)  Willy Wonka & the Chocolate Factory (1971)  \\\n",
       "userId                                                                \n",
       "user_1              3.0                                         4.0   \n",
       "user_10             3.0                                         4.0   \n",
       "user_100            3.0                                         4.0   \n",
       "user_101            3.0                                         4.0   \n",
       "user_102            3.0                                         4.0   \n",
       "...                 ...                                         ...   \n",
       "user_95             3.0                                         4.0   \n",
       "user_96             3.0                                         4.0   \n",
       "user_97             3.0                                         4.0   \n",
       "user_98             3.0                                         4.0   \n",
       "user_99             3.0                                         4.0   \n",
       "\n",
       "title     X-Men (2000)  Zombieland (2009)  \n",
       "userId                                     \n",
       "user_1             3.5                2.5  \n",
       "user_10            3.5                2.5  \n",
       "user_100           3.5                2.5  \n",
       "user_101           3.5                2.5  \n",
       "user_102           3.5                2.5  \n",
       "...                ...                ...  \n",
       "user_95            3.5                2.5  \n",
       "user_96            3.5                2.5  \n",
       "user_97            3.5                2.5  \n",
       "user_98            3.5                2.5  \n",
       "user_99            3.5                2.5  \n",
       "\n",
       "[610 rows x 75 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ratings_df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assign the arrays to variables\n",
    "sw_IV = user_ratings_df_imputed.loc[:,'Toy Story (1995)'].values.reshape(1, -1)\n",
    "sw_V = user_ratings_df_imputed.loc[:,'Aladdin (1992)'].values.reshape(1, -1)\n",
    "\n",
    "# Find the similarity between two Star Wars movies\n",
    "similarity_A = cosine_similarity(sw_IV, sw_V)\n",
    "print(similarity_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding similarities\n",
    "\n",
    "### Item-based recommendations\n",
    "It assumes if Item A and B receive similar reviews, either positive or negative,\n",
    "Then however other people feel about A, they should feel the same way about B.\n",
    "\n",
    "<img src=\"image/53.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### User-based to item-based\n",
    "We can switch between these two approaches,by transposing the matrices giving us the items as rows and the users as columns.\n",
    "\n",
    "<img src=\"image/55.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "```python\n",
    "print(user_ratings_pivot)\n",
    "```\n",
    "<img src=\"image/56.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "```python\n",
    "book_ratings_pivot = user_ratings_pivot.T\n",
    "print(book_ratings_pivot)\n",
    "```\n",
    "<img src=\"image/57.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "\n",
    "### Cosine similarities\n",
    "```python\n",
    "cosine_similarity(book_ratings_pivot.loc['Lord of the Rings', :].values.reshape(1, -1),\n",
    "book_ratings_pivot.loc['The Hobbit', :].values.reshape(1, -1))\n",
    "```\n",
    "answer:\n",
    "`0.43`\n",
    "\n",
    "```python\n",
    "cosine_similarity(book_ratngs.loc['Lord of the Rings', :].values.reshape(1, -1),\n",
    "book_ratngs.loc['Twilight', :].values.reshape(1, -1))\n",
    "```\n",
    "answer:\n",
    "`-0.64`\n",
    "\n",
    "```python\n",
    "similarities = cosine_similarity(book_ratings_pivot)\n",
    "cosine_similarity_df = pd.DataFrame(similarities,\n",
    "index=book_ratings_pivot.index,\n",
    "columns=book_ratings_pivot.index)\n",
    "cosine_similarity_df.head()\n",
    "```\n",
    "<img src=\"image/58.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "```python\n",
    "cosine_similarity_series = cosine_similarity_df.loc['The Hobbit']\n",
    "ordered_similarities = cosine_similarity_series.sort_values(ascending=False)\n",
    "print(ordered_similarities)\n",
    "```\n",
    "<img src=\"image/59.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "<img src=\"https://i1.wp.com/www.firstplaceforhealth.com/wp-content/uploads/2020/03/train-your-brain-gif-2.gif?fit=1200%2C904&ssl=1\" width=\"300\" height=\"100\">\n",
    "\n",
    "**Exercise:** Switch between the user-based and item-based and compare their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>The Sandlot</th>\n",
       "      <th>Ocean's Eleven</th>\n",
       "      <th>The Lion King</th>\n",
       "      <th>John Wick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User_A</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User_B</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User_C</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>User_D</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  The Sandlot  Ocean's Eleven  The Lion King  John Wick\n",
       "0     User_A            1               4              1          5\n",
       "1     User_B            1               5              1          4\n",
       "2     User_C            4               2              5          2\n",
       "3     User_D            4               1              4          2"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ratings_subset2=pd.read_csv('user_ratings_subset2.csv')\n",
    "user_ratings_subset2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "Based on the data in `user_ratings_subset2`, which user is most similar to `User_A`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0       1       2       3\n",
      "Unnamed: 0      User_A  User_B  User_C  User_D\n",
      "The Sandlot          1       1       4       4\n",
      "Ocean's Eleven       4       5       2       1\n",
      "The Lion King        1       1       5       4\n",
      "John Wick            5       4       2       2\n"
     ]
    }
   ],
   "source": [
    "# Transpose the user_ratings_subset DataFrame\n",
    "movie_ratings_subset = user_ratings_subset2.T\n",
    "\n",
    "print(movie_ratings_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "Based on this new transposed data, what movie appears most similar to `The Sandlot`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using K-nearest neighbors\n",
    "\n",
    "### Beyond similar items\n",
    "You are now able to find similar items based on how the users in your dataset have rated them. But what if we wanted to not only find similarly rated items, but actually predict how a user might rate an item even if it is not similar to any item they have seen! One approach is to find similar users using a K nearest neighbors model and see how they liked the item.\n",
    "\n",
    "<img src=\"image/60.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### K-nearest neighbors\n",
    "K-NN finds the k users that are closest measured by a specified metric, to the user in question. It then averages the rating those users gave the item we are trying to get a rating for.\n",
    "<img src=\"image/61.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### User-user similarity\n",
    "```python\n",
    "similarities = cosine_similarity(user_ratings_pivot)\n",
    "cosine_similarity_df = pd.DataFrame(user_ratings_pivot,\n",
    "index=user_ratings_pivot.index,\n",
    "columns=user_ratings_pivot.index)\n",
    "cosine_similarity_df.head()\n",
    "```\n",
    "<img src=\"image/62.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Step by step KNN\n",
    "\n",
    "```python\n",
    "user_similarity_series = user_similarities.loc['user_001']\n",
    "ordered_similarities = user_similarity_series.sort_values(ascending=False)\n",
    "nearest_neighbors = ordered_similarities[1:4].index\n",
    "print(nearest_neighbors)\n",
    "```\n",
    "answer:\n",
    "\n",
    "`user_007`\n",
    "`user_042`\n",
    "`user_003`\n",
    "\n",
    "```python\n",
    "neighbor_ratings = user_ratings_table.reindex(nearest_neighbors)\n",
    "neighbor_ratings['Catch-22'].mean()\n",
    "```\n",
    "answer:\n",
    "`3.2`\n",
    "\n",
    "### Using scikit-learn's KNN\n",
    "```python\n",
    "print(user_ratings_pivot)\n",
    "```\n",
    "<img src=\"image/63.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "```python\n",
    "print(user_ratings_table)\n",
    "```\n",
    "<img src=\"image/64.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "```python\n",
    "user_ratings_pivot.drop(\"Catch-22\", axis=1, inplace=True)\n",
    "target_user_x = user_ratings_pivot.loc[[\"user_001\"]]\n",
    "print(target_user_x)\n",
    "```\n",
    "<img src=\"image/65.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "```python\n",
    "other_users_y = user_ratings_table[\"Catch-22\"]\n",
    "print(other_users_y)\n",
    "```\n",
    "answer:\n",
    "`[NaN, '5.0', '3.0', '4.0', '5.0' ...]`\n",
    "\n",
    "\n",
    "```python\n",
    "other_users_x = user_ratings_pivot[other_users_y.notnull()]\n",
    "print(other_users_x)\n",
    "```\n",
    "<img src=\"image/66.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "```python\n",
    "other_users_y.dropna(inplace=True)\n",
    "print(other_users_y)\n",
    "```\n",
    "answer:\n",
    "`['5.0', '3.0', '4.0','5.0' ...]`\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "user_knn = KNeighborsRegressor(metric='cosine', n_neighbors=3)\n",
    "user_knn.fit(other_users_x, other_users_y)\n",
    "user_user_pred = user_knn.predict(target_user_x)\n",
    "print(user_user_pred)\n",
    "```\n",
    "answer:\n",
    "`3.3`\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "user_knn = KNeighborsClassifier(metric='cosine', n_neighbors=3)\n",
    "user_knn.fit(other_users_x, other_users_y)\n",
    "user_user_pred = user_knn.predict(target_user_x)\n",
    "print(user_user_pred)\n",
    "```\n",
    "answer:\n",
    "`3`\n",
    "\n",
    "<img src=\"https://i1.wp.com/www.firstplaceforhealth.com/wp-content/uploads/2020/03/train-your-brain-gif-2.gif?fit=1200%2C904&ssl=1\" width=\"300\" height=\"100\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-based or user-based\n",
    "### Item-based filtering\n",
    "\n",
    "<img src=\"image/67.PNG\" width=\"500\" height=\"100\">\n",
    "<img src=\"image/68.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Why use item-based filtering?\n",
    "#### Pros:\n",
    "- Item-based recommendations are more consistent over time\n",
    "\n",
    "        Users' preferences change, for example, you might enjoy animated movies when you are younger, but change your preferences to action movies later in life. Items on the other hand do not usually change, a movie that was a horror movie when it came out is still a horror movie years later. \n",
    "        \n",
    "- Item-based recommendations can be easier to explain\n",
    "- Item-based recommendations can be pre-calculated\n",
    "#### Cons:\n",
    "- Item-based recommendations result in very obvious suggestions\n",
    "\n",
    "### Why use user-based filtering?\n",
    "#### Pros:\n",
    "- User-based recommendations can create a lot more interesting suggestions\n",
    "\n",
    "#### Cons:\n",
    "- Generally beaten by item-based recommendations using standard metrics\n",
    "\n",
    "<img src=\"https://i1.wp.com/www.firstplaceforhealth.com/wp-content/uploads/2020/03/train-your-brain-gif-2.gif?fit=1200%2C904&ssl=1\" width=\"300\" height=\"100\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/c4.PNG\" width=\"1000\" height=\"100\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with sparsity\n",
    "- Now you are capable of not only generating recommendations for any user in your dataset, but also predicting what rating users might give items they have not come across using KNN.\n",
    "- This works great for dense datasets in which every item has been reviewed by multiple people, which ensures that the K nearest neighbors are genuinely similar to your user. But what if the data is less full?\n",
    "- This is actually a common concern in real-world rating data as the number of users and items are generally quite high and the number of reviews are quite low.\n",
    "\n",
    "### Sparse matrices\n",
    "\n",
    "We call the percentage of a DataFrame that is empty the DataFrame's sparsity. In other words, the number of empty cells over the number of cells with data.\n",
    "\n",
    "<img src=\"image/69.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Measuring sparsity\n",
    "We can check the sparsity of a DataFrame by counting the number of missing values in it using the following code. Here we see that the DataFrame is only just over 1% filled, so it's quite sparse.\n",
    "\n",
    "```python\n",
    "print(book_rating_df)\n",
    "```\n",
    "<img src=\"image/51.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "```python\n",
    "number_of_empty = book_ratings_df.isnull().values.sum()\n",
    "total_number = user_ratings_df.size\n",
    "sparsity = number_of_empty/total_number\n",
    "print(sparsity)\n",
    "```\n",
    "Answer: \n",
    "`0.0114`\n",
    "### Why sparsity matters\n",
    "\n",
    "Why does this matter? This can create problems if we were to use KNN with sparse data because KNN requires you to find the K nearest users that have rated the item. \n",
    "<img src=\"image/70.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "- Let's say we wanted to estimate what User 1 would give item 5. We would find the n nearest ratings of the item, but in this case, there are only 2 KNN or other users that have rated the item.\n",
    "- Therefore we would have to return an average of all reviews (2 in this case) because there is no other data. This does not actually take the similarities into account.\n",
    "\n",
    "\n",
    "### Measuring sparsity per column\n",
    "\n",
    "You can understand the scale of this issue by simply counting the number of actual reviews for each book using the following code. We can see that a large number of books have only received one or two reviews.\n",
    "```python\n",
    "user_ratings_df.notnull().sum()\n",
    "```\n",
    "<img src=\"image/71.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Matrix factorization\n",
    "We can leverage matrix factorization to deal with this problem remarkably well and create some quite interesting features while doing so.\n",
    "\n",
    "Matrix factorization is when we decompose the user-rating matrix into the product of two lower dimensionality matrices. These matrices shown here are factors of the original matrix on the left, if you were to find the product of the two of them it would be this original matrix. By finding factors of the sparse matrix and then multiplying them together we can be left will a fully filled matrix. \n",
    "\n",
    "<img src=\"image/72.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Matrix multiplication\n",
    "\n",
    "To multiply two rectangular matrices, the number of rows in the first matrix M here and the number of columns in the second matrix N here do not have to match but the number of columns of the first matrix must match the number of rows in the second.\n",
    "\n",
    "<img src=\"image/73.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "```python\n",
    "print(matrix_x)\n",
    "\n",
    "Answer:\n",
    "    \n",
    "[[4, 1],\n",
    "[2, 2],\n",
    "[3, 3]]\n",
    "\n",
    "print(matrix_b)\n",
    "\n",
    "Answer:\n",
    "    \n",
    "[[1, 0, 4],\n",
    "[0, 1, 6]]\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "dot_product = np.dot(matrix_x, matrix_b)\n",
    "print(dot_product)\n",
    "\n",
    "Answer:\n",
    "    \n",
    "[[ 4 1 22]\n",
    "[ 2 2 20]\n",
    "[ 3 3 30]]\n",
    "```\n",
    "<img src=\"https://i1.wp.com/www.firstplaceforhealth.com/wp-content/uploads/2020/03/train-your-brain-gif-2.gif?fit=1200%2C904&ssl=1\" width=\"300\" height=\"100\">\n",
    "\n",
    "\n",
    "**Exercise:** Calculate how sparse the movie_lens ratings data is by counting the number of occupied cells and compare it to the size of the full DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title     13th Warrior, The (1999)  Abyss, The (1989)  Aladdin (1992)  \\\n",
      "userId                                                                  \n",
      "user_1                         NaN                NaN             NaN   \n",
      "user_10                        NaN                NaN             NaN   \n",
      "user_100                       NaN                NaN             NaN   \n",
      "user_101                       NaN                NaN             NaN   \n",
      "user_102                       NaN                NaN             NaN   \n",
      "...                            ...                ...             ...   \n",
      "user_95                        NaN                NaN             NaN   \n",
      "user_96                        NaN                NaN             NaN   \n",
      "user_97                        NaN                NaN             NaN   \n",
      "user_98                        NaN                NaN             NaN   \n",
      "user_99                        NaN                NaN             NaN   \n",
      "\n",
      "title     Alice in Wonderland (1951)  Alien (1979)  Apocalypse Now (1979)  \\\n",
      "userId                                                                      \n",
      "user_1                           NaN           NaN                    NaN   \n",
      "user_10                          NaN           NaN                    NaN   \n",
      "user_100                         NaN           NaN                    NaN   \n",
      "user_101                         NaN           NaN                    NaN   \n",
      "user_102                         NaN           NaN                    NaN   \n",
      "...                              ...           ...                    ...   \n",
      "user_95                          NaN           NaN                    NaN   \n",
      "user_96                          NaN           NaN                    NaN   \n",
      "user_97                          NaN           NaN                    NaN   \n",
      "user_98                          NaN           NaN                    NaN   \n",
      "user_99                          NaN           NaN                    NaN   \n",
      "\n",
      "title     Austin Powers: International Man of Mystery (1997)  Bambi (1942)  \\\n",
      "userId                                                                       \n",
      "user_1                                                  NaN            NaN   \n",
      "user_10                                                 NaN            NaN   \n",
      "user_100                                                NaN            NaN   \n",
      "user_101                                                NaN            NaN   \n",
      "user_102                                                NaN            NaN   \n",
      "...                                                     ...            ...   \n",
      "user_95                                                 NaN            NaN   \n",
      "user_96                                                 NaN            NaN   \n",
      "user_97                                                 NaN            NaN   \n",
      "user_98                                                 NaN            NaN   \n",
      "user_99                                                 NaN            NaN   \n",
      "\n",
      "title     Basic Instinct (1992)  Batman (1989)  ...  \\\n",
      "userId                                          ...   \n",
      "user_1                      NaN            NaN  ...   \n",
      "user_10                     NaN            NaN  ...   \n",
      "user_100                    NaN            NaN  ...   \n",
      "user_101                    NaN            NaN  ...   \n",
      "user_102                    NaN            NaN  ...   \n",
      "...                         ...            ...  ...   \n",
      "user_95                     NaN            NaN  ...   \n",
      "user_96                     NaN            NaN  ...   \n",
      "user_97                     NaN            NaN  ...   \n",
      "user_98                     NaN            NaN  ...   \n",
      "user_99                     NaN            NaN  ...   \n",
      "\n",
      "title     Three Musketeers, The (1993)  Tommy Boy (1995)  Toy Story (1995)  \\\n",
      "userId                                                                       \n",
      "user_1                             NaN               NaN               4.0   \n",
      "user_10                            NaN               NaN               NaN   \n",
      "user_100                           NaN               NaN               NaN   \n",
      "user_101                           NaN               NaN               NaN   \n",
      "user_102                           NaN               NaN               NaN   \n",
      "...                                ...               ...               ...   \n",
      "user_95                            NaN               NaN               NaN   \n",
      "user_96                            NaN               NaN               5.0   \n",
      "user_97                            NaN               NaN               NaN   \n",
      "user_98                            NaN               NaN               4.5   \n",
      "user_99                            NaN               NaN               NaN   \n",
      "\n",
      "title     Toys (1992)  Usual Suspects, The (1995)  Wild Things (1998)  \\\n",
      "userId                                                                  \n",
      "user_1            NaN                         NaN                 NaN   \n",
      "user_10           NaN                         NaN                 NaN   \n",
      "user_100          NaN                         NaN                 NaN   \n",
      "user_101          NaN                         NaN                 NaN   \n",
      "user_102          NaN                         NaN                 NaN   \n",
      "...               ...                         ...                 ...   \n",
      "user_95           NaN                         NaN                 NaN   \n",
      "user_96           NaN                         NaN                 NaN   \n",
      "user_97           NaN                         NaN                 NaN   \n",
      "user_98           NaN                         NaN                 NaN   \n",
      "user_99           NaN                         NaN                 NaN   \n",
      "\n",
      "title     Willow (1988)  Willy Wonka & the Chocolate Factory (1971)  \\\n",
      "userId                                                                \n",
      "user_1              NaN                                         NaN   \n",
      "user_10             NaN                                         NaN   \n",
      "user_100            NaN                                         NaN   \n",
      "user_101            NaN                                         NaN   \n",
      "user_102            NaN                                         NaN   \n",
      "...                 ...                                         ...   \n",
      "user_95             NaN                                         NaN   \n",
      "user_96             NaN                                         NaN   \n",
      "user_97             NaN                                         NaN   \n",
      "user_98             NaN                                         NaN   \n",
      "user_99             NaN                                         NaN   \n",
      "\n",
      "title     X-Men (2000)  Zombieland (2009)  \n",
      "userId                                     \n",
      "user_1             NaN                NaN  \n",
      "user_10            NaN                NaN  \n",
      "user_100           NaN                NaN  \n",
      "user_101           NaN                NaN  \n",
      "user_102           NaN                NaN  \n",
      "...                ...                ...  \n",
      "user_95            NaN                NaN  \n",
      "user_96            NaN                NaN  \n",
      "user_97            NaN                NaN  \n",
      "user_98            NaN                NaN  \n",
      "user_99            NaN                NaN  \n",
      "\n",
      "[610 rows x 75 columns]\n"
     ]
    }
   ],
   "source": [
    "user_ratings_pivot = user_ratings.pivot(index='userId',\n",
    "columns='title',\n",
    "values='rating')\n",
    "print(user_ratings_pivot)\n",
    "user_ratings_df=user_ratings_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "# Count the occupied cells\n",
    "sparsity_count = user_ratings_df.isnull().values.sum()\n",
    "\n",
    "# Count all cells\n",
    "full_count = user_ratings_df.size\n",
    "\n",
    "# Find the sparsity of the DataFrame\n",
    "sparsity = sparsity_count / full_count\n",
    "print(sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Count how often each movie in the user_ratings_df DataFrame has been given a rating, and then see how many have only one or two ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n",
      "13th Warrior, The (1999)                      1\n",
      "Abyss, The (1989)                             3\n",
      "Aladdin (1992)                                1\n",
      "Alice in Wonderland (1951)                    1\n",
      "Alien (1979)                                  2\n",
      "                                             ..\n",
      "Wild Things (1998)                            1\n",
      "Willow (1988)                                 1\n",
      "Willy Wonka & the Chocolate Factory (1971)    1\n",
      "X-Men (2000)                                  1\n",
      "Zombieland (2009)                             1\n",
      "Length: 75, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the occupied cells per column\n",
    "occupied_count = user_ratings_df.notnull().sum()\n",
    "print(occupied_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n",
      "13th Warrior, The (1999)                          1\n",
      "Henry V (1989)                                    1\n",
      "Highlander (1986)                                 1\n",
      "I Still Know What You Did Last Summer (1998)      1\n",
      "X-Men (2000)                                      1\n",
      "                                               ... \n",
      "Heat (1995)                                      35\n",
      "Braveheart (1995)                                41\n",
      "Usual Suspects, The (1995)                       48\n",
      "Seven (a.k.a. Se7en) (1995)                      74\n",
      "Toy Story (1995)                                215\n",
      "Length: 75, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Sort the resulting series from low to high\n",
    "sorted_occupied_count = occupied_count.sort_values()\n",
    "print(sorted_occupied_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a histogram of the values in sorted_occupied_count\n",
    "sorted_occupied_count.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix multiplication**\n",
    "\n",
    "<img src=\"image/85.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "Image of a tall rectangular matrix being multiplied by a wide rectangular matrix When multiplying an 10 x 30 matrix by a 30 x 40 matrix, what size matrix is generated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix factorization\n",
    "### Why this helps with sparse matrices\n",
    "\n",
    "A huge benefit of this, when performed in conjunction with recommendation systems, is that factors can be found as long as there is at least one value in every row and column. Or in other words every user has given at least one rating, and every item has been rated at least once. Why is this valuable? Because we can multiply these factors together to create a fully filled in matrix.\n",
    "<img src=\"image/72.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### What matrix factorization looks like\n",
    "\n",
    "Matrix factorization breaks a matrix into two component matrices. Take a rating matrix with M users as rows and the N items they rated as the columns. Matrix factorization will break this down into one matrix with its depth equal to the number of users and one matrix with its width equal to the number of items.\n",
    "The number of values in the newly created dimensions shown here are called the rank of the matrix and must be equal to each other and can be decided by us. These new unlabeled columns and rows are called latent features. These are the features that the matrix factorization view as mathematically the best ways to describe or sum up this dataset in the least number of features.\n",
    "\n",
    "<img src=\"image/74.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Latent features\n",
    "To explain what that entails, let's take a closer look at a small example. Here we see four users and how they have rated six books and the decomposed version of the ratings matrix. You can see that the original matrix has six columns but the first matrix that is a factor only has two columns.\n",
    "\n",
    "Taking a look at latent feature 1, we can see that users who gave high ratings to horror and fantasy books got relatively high values for this feature, while for latent feature 2, a high value appears to correspond with users who preferred romance novels. This is a simplified example, and often latent features become harder to label with larger datasets, but these are features that the matrix factorization has calculated as representing patterns in the original matrix.\n",
    "\n",
    "\n",
    "<img src=\"image/75.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Information loss\n",
    "One question that might come to mind when you see these large DataFrames being reduced to much smaller factor matrices is, how can it do this without losing information? In reality, you can't reduce down these matrices without at least some information loss - these factors are just close approximations of the original data. If we were to multiply the factors back together\n",
    "we would actually see a slight difference between the first and last matrix. Even the values we had originally may be off by a small fraction. \n",
    "<img src=\"image/76.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "\n",
    "<img src=\"https://i1.wp.com/www.firstplaceforhealth.com/wp-content/uploads/2020/03/train-your-brain-gif-2.gif?fit=1200%2C904&ssl=1\" width=\"300\" height=\"100\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Alien</th>\n",
       "      <th>Scream</th>\n",
       "      <th>Love Actually</th>\n",
       "      <th>The Notebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User_1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User_2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User_3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>User_4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User_5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  Alien  Scream  Love Actually  The Notebook\n",
       "0     User_1      5       4              2             1\n",
       "1     User_2      2       1              4             5\n",
       "2     User_3      1       3              5             4\n",
       "3     User_4      4       5              1             2\n",
       "4     User_5      1       1              5             5"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df=pd.read_csv('original_df.csv')\n",
    "original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.9202913 ,  5.43628339],\n",
       "       [ 2.01738539,  6.37262296],\n",
       "       [ 1.46328822,  6.84850675],\n",
       "       [-3.88683688,  5.47272837],\n",
       "       [ 3.00873893,  6.54960159]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "user_matrix=np.array([[-3.9202913 ,  5.43628339],\n",
    "                       [ 2.01738539,  6.37262296],\n",
    "                       [ 1.46328822,  6.84850675],\n",
    "                       [-3.88683688,  5.47272837],\n",
    "                       [ 3.00873893,  6.54960159]])\n",
    "user_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the values in the first column of the `user_matrix`, what do you think the latent feature may be summarizing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Inspect the same original pre-factorization DataFrame from the last exercise loaded as `original_df`, and compare it to the product of its two factors, `user_matrix` and `item_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.99975739 4.00002482 3.00049612 1.9999559  0.99971309]\n",
      " [1.94609518 1.00551231 4.11024369 3.99020215 4.93625285]\n",
      " [0.97027582 3.00303961 3.06079052 4.99459728 3.96484857]\n",
      " [4.01506891 4.99845908 2.96918167 1.00273896 2.01782031]\n",
      " [1.06960907 0.99288186 3.85763861 5.01265224 5.08231879]]\n",
      "  Unnamed: 0  Alien  Scream  Love Actually  The Notebook\n",
      "0     User_1      5       4              2             1\n",
      "1     User_2      2       1              4             5\n",
      "2     User_3      1       3              5             4\n",
      "3     User_4      4       5              1             2\n",
      "4     User_5      1       1              5             5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "item_matrix=np.array([[-0.31315676,  0.27223577,  0.11236206, -0.6851852 ,  0.58797665],\n",
    "       [ 0.53506273, -0.67846698,  0.34679691, -0.33676863,  0.14038957],\n",
    "       [-0.58681644, -0.56753532,  0.01699735,  0.40147032,  0.41482863],\n",
    "       [ 0.34689509,  0.37669009,  0.48522268,  0.50094181,  0.50138271]])\n",
    "\n",
    "user_matrix=np.array([[-0.92214831,  0.46868881, -3.93546218,  6.20017019],\n",
    "       [ 0.29451291,  1.1337195 ,  2.00684562,  7.52205181],\n",
    "       [-0.23338272, -1.58223229,  1.42823577,  7.4428733 ],\n",
    "       [ 0.93640606, -0.2676827 , -3.90282275,  6.23040608],\n",
    "       [-0.07751554,  0.26188815,  2.99513239,  7.67609853]])\n",
    "\n",
    "# Multiply the user and item matrices\n",
    "predictions_df = np.dot(user_matrix, item_matrix)\n",
    "# Inspect the recreated DataFrame\n",
    "print(predictions_df)\n",
    "\n",
    "# Inspect the original DataFrame and compare\n",
    "print(original_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular value decomposition (SVD)\n",
    "### What SVD does\n",
    "Singular value decomposition finds factors for your matrix.\n",
    "U is the user matrix V transpose is the features matrix (transpose in this case means that V has been flipped over its diagonal, but we do not need to worry about that here) but it also generates sigma as seen here, which is simply a diagonal matrix which can be thought of as the weights of the latent features, or how large an impact they are calculated to have.\n",
    "\n",
    "<img src=\"image/77.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Prepping our data\n",
    "\n",
    "```python\n",
    "print(book_ratings_df.shape)\n",
    "```\n",
    "answer:\n",
    "`(220, 500)`\n",
    "\n",
    "```python\n",
    "avg_ratings = book_ratings_df.mean(axis=1)\n",
    "print(avg_ratings)\n",
    "\n",
    "answer:\n",
    "array([[4.5 ],\n",
    "[3.5],\n",
    "[2.5],\n",
    "[3.5],\n",
    "...\n",
    "[2.2]])\n",
    "```\n",
    "\n",
    "```python\n",
    "user_ratings_pivot_centered = user_ratings_df.sub(avg_ratings, axis=0)\n",
    "user_ratings_df.fillna(0, inplace=True)\n",
    "print(user_ratings_df)\n",
    "```\n",
    "<img src=\"image/52.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Applying SVD\n",
    "```python\n",
    "from scipy.sparse.linalg import svds\n",
    "U, sigma, Vt = svds(user_ratings_pivot_centered)\n",
    "print(U.shape)\n",
    "```\n",
    "amswer:\n",
    "`(610, 6)`\n",
    "```python\n",
    "print(Vt.shape)\n",
    "```\n",
    "answer:\n",
    "`(6, 1000)`\n",
    "\n",
    "```python\n",
    "print(sigma)\n",
    "```\n",
    "`[3.0, 4.8, -12.6, -3.8, 8.2, 7.3]`\n",
    "\n",
    "```python\n",
    "sigma = np.diag(sigma)\n",
    "print(sigma)\n",
    "\n",
    "answer:\n",
    "array([ 3.0 , 0. , 0. , 0. , 0. , 0. ],\n",
    "[ 0. , 4.8 , 0. , 0. , 0. , 0. ],\n",
    "[ 0. , 0. , -12.6 , 0. , 0. , 0. ],\n",
    "[ 0. , 0. , 0. , -3.8 , 0. , 0. ],\n",
    "[ 0. , 0. , 0. , 0. , 8.2 , 0. ],\n",
    "[ 0. , 0. , 0. , 0. , 0. , 7.3 ]),\n",
    "```\n",
    "### Getting the final matrix\n",
    "<img src=\"image/78.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Calculating the product in Python\n",
    "```python\n",
    "recalculated_ratings = np.dot(np.dot(U, sigma), Vt)\n",
    "print(recalculated_ratings)\n",
    "\n",
    "answer:\n",
    "[[ 0.1 -0.9 -3.6. ... ]\n",
    "[ -2.3 0.5 -0.5 ... ]\n",
    "[ 0.5 -0.5 2.0 ... ]\n",
    "[ ... ... ... ... ]]\n",
    "```\n",
    "### Add averages back\n",
    "```python\n",
    "recalculated_ratings = recalculated_ratings + avg_ratings.values.reshape(-1, 1)\n",
    "print(recalculated_ratings)\n",
    "\n",
    "answer:\n",
    "[[ 4.6 3.6 0.9 ... ]\n",
    "[ 1.8 4.0 3.0 ... ]\n",
    "[ 3.0 2.0 4.5 ... ]\n",
    "[ ... ... ... ... ]]\n",
    "\n",
    "print(book_ratings_df)\n",
    "\n",
    "answer:\n",
    "[[ 5.0 4.0 NA ... ]\n",
    "[ NA 4.0 3.0 ... ]\n",
    "[ 3.0 2.0 NA ... ]\n",
    "[ ... ... ... ... ]]\n",
    "```\n",
    "\n",
    "<img src=\"https://i1.wp.com/www.firstplaceforhealth.com/wp-content/uploads/2020/03/train-your-brain-gif-2.gif?fit=1200%2C904&ssl=1\" width=\"300\" height=\"100\">\n",
    "\n",
    "**Exercise:** Begin prepping the movie rating DataFrame you have been working with in order to be able to perform Singular value decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>title</th>\n",
       "      <th>13th Warrior, The (1999)</th>\n",
       "      <th>Abyss, The (1989)</th>\n",
       "      <th>Aladdin (1992)</th>\n",
       "      <th>Alice in Wonderland (1951)</th>\n",
       "      <th>Alien (1979)</th>\n",
       "      <th>Apocalypse Now (1979)</th>\n",
       "      <th>Austin Powers: International Man of Mystery (1997)</th>\n",
       "      <th>Bambi (1942)</th>\n",
       "      <th>Basic Instinct (1992)</th>\n",
       "      <th>Batman (1989)</th>\n",
       "      <th>...</th>\n",
       "      <th>Three Musketeers, The (1993)</th>\n",
       "      <th>Tommy Boy (1995)</th>\n",
       "      <th>Toy Story (1995)</th>\n",
       "      <th>Toys (1992)</th>\n",
       "      <th>Usual Suspects, The (1995)</th>\n",
       "      <th>Wild Things (1998)</th>\n",
       "      <th>Willow (1988)</th>\n",
       "      <th>Willy Wonka &amp; the Chocolate Factory (1971)</th>\n",
       "      <th>X-Men (2000)</th>\n",
       "      <th>Zombieland (2009)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_95</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_96</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "title     13th Warrior, The (1999)  Abyss, The (1989)  Aladdin (1992)  \\\n",
       "userId                                                                  \n",
       "user_1                         0.0                0.0             0.0   \n",
       "user_10                        0.0                0.0             0.0   \n",
       "user_100                       0.0                0.0             0.0   \n",
       "user_101                       0.0                0.0             0.0   \n",
       "user_102                       0.0                0.0             0.0   \n",
       "...                            ...                ...             ...   \n",
       "user_95                        0.0                0.0             0.0   \n",
       "user_96                        0.0                0.0             0.0   \n",
       "user_97                        0.0                0.0             0.0   \n",
       "user_98                        0.0                0.0             0.0   \n",
       "user_99                        0.0                0.0             0.0   \n",
       "\n",
       "title     Alice in Wonderland (1951)  Alien (1979)  Apocalypse Now (1979)  \\\n",
       "userId                                                                      \n",
       "user_1                           0.0           0.0                    0.0   \n",
       "user_10                          0.0           0.0                    0.0   \n",
       "user_100                         0.0           0.0                    0.0   \n",
       "user_101                         0.0           0.0                    0.0   \n",
       "user_102                         0.0           0.0                    0.0   \n",
       "...                              ...           ...                    ...   \n",
       "user_95                          0.0           0.0                    0.0   \n",
       "user_96                          0.0           0.0                    0.0   \n",
       "user_97                          0.0           0.0                    0.0   \n",
       "user_98                          0.0           0.0                    0.0   \n",
       "user_99                          0.0           0.0                    0.0   \n",
       "\n",
       "title     Austin Powers: International Man of Mystery (1997)  Bambi (1942)  \\\n",
       "userId                                                                       \n",
       "user_1                                                  0.0            0.0   \n",
       "user_10                                                 0.0            0.0   \n",
       "user_100                                                0.0            0.0   \n",
       "user_101                                                0.0            0.0   \n",
       "user_102                                                0.0            0.0   \n",
       "...                                                     ...            ...   \n",
       "user_95                                                 0.0            0.0   \n",
       "user_96                                                 0.0            0.0   \n",
       "user_97                                                 0.0            0.0   \n",
       "user_98                                                 0.0            0.0   \n",
       "user_99                                                 0.0            0.0   \n",
       "\n",
       "title     Basic Instinct (1992)  Batman (1989)  ...  \\\n",
       "userId                                          ...   \n",
       "user_1                      0.0            0.0  ...   \n",
       "user_10                     0.0            0.0  ...   \n",
       "user_100                    0.0            0.0  ...   \n",
       "user_101                    0.0            0.0  ...   \n",
       "user_102                    0.0            0.0  ...   \n",
       "...                         ...            ...  ...   \n",
       "user_95                     0.0            0.0  ...   \n",
       "user_96                     0.0            0.0  ...   \n",
       "user_97                     0.0            0.0  ...   \n",
       "user_98                     0.0            0.0  ...   \n",
       "user_99                     0.0            0.0  ...   \n",
       "\n",
       "title     Three Musketeers, The (1993)  Tommy Boy (1995)  Toy Story (1995)  \\\n",
       "userId                                                                       \n",
       "user_1                             0.0               0.0               4.0   \n",
       "user_10                            0.0               0.0               0.0   \n",
       "user_100                           0.0               0.0               0.0   \n",
       "user_101                           0.0               0.0               0.0   \n",
       "user_102                           0.0               0.0               0.0   \n",
       "...                                ...               ...               ...   \n",
       "user_95                            0.0               0.0               0.0   \n",
       "user_96                            0.0               0.0               5.0   \n",
       "user_97                            0.0               0.0               0.0   \n",
       "user_98                            0.0               0.0               4.5   \n",
       "user_99                            0.0               0.0               0.0   \n",
       "\n",
       "title     Toys (1992)  Usual Suspects, The (1995)  Wild Things (1998)  \\\n",
       "userId                                                                  \n",
       "user_1            0.0                         0.0                 0.0   \n",
       "user_10           0.0                         0.0                 0.0   \n",
       "user_100          0.0                         0.0                 0.0   \n",
       "user_101          0.0                         0.0                 0.0   \n",
       "user_102          0.0                         0.0                 0.0   \n",
       "...               ...                         ...                 ...   \n",
       "user_95           0.0                         0.0                 0.0   \n",
       "user_96           0.0                         0.0                 0.0   \n",
       "user_97           0.0                         0.0                 0.0   \n",
       "user_98           0.0                         0.0                 0.0   \n",
       "user_99           0.0                         0.0                 0.0   \n",
       "\n",
       "title     Willow (1988)  Willy Wonka & the Chocolate Factory (1971)  \\\n",
       "userId                                                                \n",
       "user_1              0.0                                         0.0   \n",
       "user_10             0.0                                         0.0   \n",
       "user_100            0.0                                         0.0   \n",
       "user_101            0.0                                         0.0   \n",
       "user_102            0.0                                         0.0   \n",
       "...                 ...                                         ...   \n",
       "user_95             0.0                                         0.0   \n",
       "user_96             0.0                                         0.0   \n",
       "user_97             0.0                                         0.0   \n",
       "user_98             0.0                                         0.0   \n",
       "user_99             0.0                                         0.0   \n",
       "\n",
       "title     X-Men (2000)  Zombieland (2009)  \n",
       "userId                                     \n",
       "user_1             0.0                0.0  \n",
       "user_10            0.0                0.0  \n",
       "user_100           0.0                0.0  \n",
       "user_101           0.0                0.0  \n",
       "user_102           0.0                0.0  \n",
       "...                ...                ...  \n",
       "user_95            0.0                0.0  \n",
       "user_96            0.0                0.0  \n",
       "user_97            0.0                0.0  \n",
       "user_98            0.0                0.0  \n",
       "user_99            0.0                0.0  \n",
       "\n",
       "[610 rows x 75 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill in all missing values with 0s\n",
    "user_ratings_df.fillna(0, inplace=True)\n",
    "user_ratings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Break the `user_ratings_df` data you generated in the last exercise into 3 factors: `U`, `sigma`, and `Vt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Use numpy's dot product function to multiply `U` and `sigma` first, then the result by `Vt`. You will then be able add the average ratings for each row to find your final ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21.70829335  0.          0.          0.          0.          0.        ]\n",
      " [ 0.         24.58149711  0.          0.          0.          0.        ]\n",
      " [ 0.          0.         26.82815685  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         29.75315109  0.          0.        ]\n",
      " [ 0.          0.          0.          0.         35.28455753  0.        ]\n",
      " [ 0.          0.          0.          0.          0.         58.77499468]]\n"
     ]
    }
   ],
   "source": [
    "# Import the required libraries \n",
    "from scipy.sparse.linalg import svds\n",
    "import numpy as np\n",
    "\n",
    "# Decompose the matrix\n",
    "U, sigma, Vt = svds(user_ratings_df)\n",
    "\n",
    "# Convert sigma into a diagonal matrix\n",
    "sigma = np.diag(sigma)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title     13th Warrior, The (1999)  Abyss, The (1989)  Aladdin (1992)  \\\n",
      "userId                                                                  \n",
      "user_1                         4.0                4.0             4.0   \n",
      "user_10                        1.0                1.0             1.0   \n",
      "user_100                       3.5                3.5             3.5   \n",
      "user_101                       4.0                4.0             4.0   \n",
      "user_102                       5.0                5.0             5.0   \n",
      "...                            ...                ...             ...   \n",
      "user_95                        5.0                5.0             5.0   \n",
      "user_96                        5.0                5.0             5.0   \n",
      "user_97                        5.0                5.0             5.0   \n",
      "user_98                        4.5                4.5             4.5   \n",
      "user_99                        5.0                5.0             5.0   \n",
      "\n",
      "title     Alice in Wonderland (1951)  Alien (1979)  Apocalypse Now (1979)  \\\n",
      "userId                                                                      \n",
      "user_1                           4.0           4.0                    4.0   \n",
      "user_10                          1.0           1.0                    1.0   \n",
      "user_100                         3.5           3.5                    3.5   \n",
      "user_101                         4.0           4.0                    4.0   \n",
      "user_102                         5.0           5.0                    5.0   \n",
      "...                              ...           ...                    ...   \n",
      "user_95                          5.0           5.0                    5.0   \n",
      "user_96                          5.0           5.0                    5.0   \n",
      "user_97                          5.0           5.0                    5.0   \n",
      "user_98                          4.5           4.5                    4.5   \n",
      "user_99                          5.0           5.0                    5.0   \n",
      "\n",
      "title     Austin Powers: International Man of Mystery (1997)  Bambi (1942)  \\\n",
      "userId                                                                       \n",
      "user_1                                                  4.0            4.0   \n",
      "user_10                                                 1.0            1.0   \n",
      "user_100                                                3.5            3.5   \n",
      "user_101                                                4.0            4.0   \n",
      "user_102                                                5.0            5.0   \n",
      "...                                                     ...            ...   \n",
      "user_95                                                 5.0            5.0   \n",
      "user_96                                                 5.0            5.0   \n",
      "user_97                                                 5.0            5.0   \n",
      "user_98                                                 4.5            4.5   \n",
      "user_99                                                 5.0            5.0   \n",
      "\n",
      "title     Basic Instinct (1992)  Batman (1989)  ...  \\\n",
      "userId                                          ...   \n",
      "user_1                      4.0            4.0  ...   \n",
      "user_10                     1.0            1.0  ...   \n",
      "user_100                    3.5            3.5  ...   \n",
      "user_101                    4.0            4.0  ...   \n",
      "user_102                    5.0            5.0  ...   \n",
      "...                         ...            ...  ...   \n",
      "user_95                     5.0            5.0  ...   \n",
      "user_96                     5.0            5.0  ...   \n",
      "user_97                     5.0            5.0  ...   \n",
      "user_98                     4.5            4.5  ...   \n",
      "user_99                     5.0            5.0  ...   \n",
      "\n",
      "title     Three Musketeers, The (1993)  Tommy Boy (1995)  Toy Story (1995)  \\\n",
      "userId                                                                       \n",
      "user_1                             4.0               4.0               8.0   \n",
      "user_10                            1.0               1.0               1.0   \n",
      "user_100                           3.5               3.5               3.5   \n",
      "user_101                           4.0               4.0               4.0   \n",
      "user_102                           5.0               5.0               5.0   \n",
      "...                                ...               ...               ...   \n",
      "user_95                            5.0               5.0               5.0   \n",
      "user_96                            5.0               5.0              10.0   \n",
      "user_97                            5.0               5.0               5.0   \n",
      "user_98                            4.5               4.5               9.0   \n",
      "user_99                            5.0               5.0               5.0   \n",
      "\n",
      "title     Toys (1992)  Usual Suspects, The (1995)  Wild Things (1998)  \\\n",
      "userId                                                                  \n",
      "user_1            4.0                         4.0                 4.0   \n",
      "user_10           1.0                         1.0                 1.0   \n",
      "user_100          3.5                         3.5                 3.5   \n",
      "user_101          4.0                         4.0                 4.0   \n",
      "user_102          5.0                         5.0                 5.0   \n",
      "...               ...                         ...                 ...   \n",
      "user_95           5.0                         5.0                 5.0   \n",
      "user_96           5.0                         5.0                 5.0   \n",
      "user_97           5.0                         5.0                 5.0   \n",
      "user_98           4.5                         4.5                 4.5   \n",
      "user_99           5.0                         5.0                 5.0   \n",
      "\n",
      "title     Willow (1988)  Willy Wonka & the Chocolate Factory (1971)  \\\n",
      "userId                                                                \n",
      "user_1              4.0                                         4.0   \n",
      "user_10             1.0                                         1.0   \n",
      "user_100            3.5                                         3.5   \n",
      "user_101            4.0                                         4.0   \n",
      "user_102            5.0                                         5.0   \n",
      "...                 ...                                         ...   \n",
      "user_95             5.0                                         5.0   \n",
      "user_96             5.0                                         5.0   \n",
      "user_97             5.0                                         5.0   \n",
      "user_98             4.5                                         4.5   \n",
      "user_99             5.0                                         5.0   \n",
      "\n",
      "title     X-Men (2000)  Zombieland (2009)  \n",
      "userId                                     \n",
      "user_1             4.0                4.0  \n",
      "user_10            1.0                1.0  \n",
      "user_100           3.5                3.5  \n",
      "user_101           4.0                4.0  \n",
      "user_102           5.0                5.0  \n",
      "...                ...                ...  \n",
      "user_95            5.0                5.0  \n",
      "user_96            5.0                5.0  \n",
      "user_97            5.0                5.0  \n",
      "user_98            4.5                4.5  \n",
      "user_99            5.0                5.0  \n",
      "\n",
      "[610 rows x 75 columns]\n",
      "  Unnamed: 0  Alien  Scream  Love Actually  The Notebook\n",
      "0     User_1      5       4              2             1\n",
      "1     User_2      2       1              4             5\n",
      "2     User_3      1       3              5             4\n",
      "3     User_4      4       5              1             2\n",
      "4     User_5      1       1              5             5\n"
     ]
    }
   ],
   "source": [
    "# Dot product of U and sigma\n",
    "U_sigma = np.dot(U, sigma)\n",
    "\n",
    "# Dot product of result and Vt\n",
    "U_sigma_Vt = np.dot(U_sigma, Vt)\n",
    "\n",
    "# Add back on the row means contained in avg_ratings\n",
    "uncentered_ratings = U_sigma_Vt + avg_ratings.values.reshape(-1, 1)\n",
    "\n",
    "# Create DataFrame of the results\n",
    "calc_pred_ratings_df = pd.DataFrame(uncentered_ratings, \n",
    "                                    index=user_ratings_df.index,\n",
    "                                    columns=user_ratings_df.columns\n",
    "                                   )\n",
    "# Print both the recalculated matrix and the original \n",
    "print(calc_pred_ratings_df)\n",
    "print(original_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Using calc_pred_ratings_df that you generated in the last exercise, with all rows and columns filled, find the movies that User_5 is most likely to enjoy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n",
      "Star Wars: Episode IV - A New Hope (1977)    5.0\n",
      "Braveheart (1995)                            5.0\n",
      "Usual Suspects, The (1995)                   5.0\n",
      "Zombieland (2009)                            5.0\n",
      "Forrest Gump (1994)                          5.0\n",
      "Name: user_102, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Sort the ratings of User 5 from high to low\n",
    "user_5_ratings = calc_pred_ratings_df.loc['user_102',:].sort_values(ascending=False)\n",
    "\n",
    "print(user_5_ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating your predictions\n",
    "### Hold-out sets\n",
    "What makes recommendation engines a little different when measuring predictions is that in more traditional machine learning models, you are trying to predict a single feature or column, but with recommendation engines, what you are trying to predict is far more inconsistent.\n",
    "Almost every user has reviewed different items, and each item has received reviews from different groups of users.\n",
    "For this reason, we cannot split our holdout set in the same way that we can for typical machine learning. In those cases, we would just split off a proportion of the row and use them to test our predictions as you see on the left.\n",
    "For recommendation engines, on the other hand, we need to remove a different chunk of the DataFrame, as seen on the right.\n",
    "\n",
    "<img src=\"image/79.PNG\" width=\"500\" height=\"100\">\n",
    "<img src=\"image/80.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "### Separating the hold-out set\n",
    "```python\n",
    "actual_values = act_ratings_df.iloc[:20, :100].values\n",
    "act_ratings_df.iloc[:20, :100] = np.nan\n",
    "```\n",
    "Generate predictions as before.\n",
    "```python\n",
    "predicted_values = calc_pred_ratings_df.iloc[:20, :100].values\n",
    "```\n",
    "\n",
    "### Masking the hold-out set\n",
    "```python\n",
    "mask = ~np.isnan(actual_values)\n",
    "print(actual_values[mask])\n",
    "```\n",
    "answer:\n",
    "`[4. 4. 5. 3. 3. ...]`\n",
    "\n",
    "```python\n",
    "print(predicted_values[mask])```\n",
    "\n",
    "answer:\n",
    "`[3.76, 4.35, 4.95, 3.5869079 3.686337 ...]`\n",
    "\n",
    "### Introducing RMSE (root mean squared error)\n",
    "The metric most commonly used to measure how good a model is at predicting a recommendation is called root mean square error or RMSE for short.\n",
    "With RMSE, we first calculate how far from the ground truth each prediction was (this is the error part in RMSE).\n",
    "We then square this as we only care about how wrong it is, not in what direction.\n",
    "We then find the average square error.\n",
    "This gives us a good measure of how close a set of predictions are to the actual values, and is very useful to compare between models.\n",
    "<img src=\"image/81.PNG\" width=\"500\" height=\"100\">\n",
    "<img src=\"image/82.PNG\" width=\"500\" height=\"100\">\n",
    "\n",
    "<img src=\"https://i1.wp.com/www.firstplaceforhealth.com/wp-content/uploads/2020/03/train-your-brain-gif-2.gif?fit=1200%2C904&ssl=1\" width=\"300\" height=\"100\">\n",
    "\n",
    "### RMSE in Python\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(actual_values[mask],\n",
    "predicted_values[mask],\n",
    "squared=False))\n",
    "```\n",
    "answer:\n",
    "`3.6223997`\n",
    "\n",
    "**Exercise: Calculating RMSE**\n",
    "The following data has been loaded in the DataFrame predictions. Either manually, or using the Python console, calculate what the root mean square error (RMSE) of these predictions is.\n",
    "\n",
    "<img src=\"image/86.PNG\" width=\"500\" height=\"100\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
